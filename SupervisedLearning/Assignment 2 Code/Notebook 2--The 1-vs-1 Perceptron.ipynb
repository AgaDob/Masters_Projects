{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics.pairwise import polynomial_kernel\n",
    "from numpy.linalg import inv, norm\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from numpy import mean\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data from csv\n",
    "Store the data as a numpy array. \\\n",
    "Shape of the full dataset: \n",
    "9298 observations (rows), 257 cols, where column 1 corresponds to the true label of the digit, while the cols 2:257 store greyscale values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import to df\n",
    "data_df = pd.read_csv(\"zipcombo2.csv\")\n",
    "\n",
    "# Convert to array to facilitate vectorization later\n",
    "data = data_df.to_numpy()\n",
    "X = data[:, 1:]\n",
    "y = data[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def efficient_poly_matrix(X_i, X_j, d):\n",
    "    \n",
    "    K = polynomial_kernel(X_i, Y=X_j, degree=d)\n",
    "    \n",
    "    return K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_matrix(X, X_, d):\n",
    "    \n",
    "    K = euclidean_distances(X,X_)\n",
    "    K_mat = np.exp(-d*K**2)\n",
    "    \n",
    "    return K_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign(pred):\n",
    "    \n",
    "    if pred <= 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-compute indexing conventions for the 45 pairwise classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classification convention**\n",
    "\n",
    "We use a convention whereby the digit in the first column is treated as the positive class and the digit in the second column as the negative class. \n",
    "\n",
    "For instance, for a [3,8] classifier 3 is thresholded as +1 and 8 as -1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**classifiers: The pairs considered in each of the 45 classifiers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "combos = []\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        if i != j:\n",
    "            combos.append([i,j])\n",
    "for i in combos:\n",
    "    i.sort()\n",
    "classifiers = [list(y) for y in set([tuple(x) for x in combos])]\n",
    "classifiers.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### digit_indexes: which alphas to index for each digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the indexes for each of the digits\n",
    "# Each of the nested lists corresponds to a specific digit.\n",
    "# eg. digit_indexes[8] contains the indexes of all the  \n",
    "# classifiers which classify for 8\n",
    "\n",
    "digit_indexes = []\n",
    "for digit in range(10):\n",
    "    digit_ind = []\n",
    "    for j in classifiers:\n",
    "        if digit in j:\n",
    "            digit_ind.append(classifiers.index(j))\n",
    "    digit_indexes.append(digit_ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### digit_classifiers: the 2 digits each classifier considers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = np.array(classifiers)\n",
    "digit_classifiers = []\n",
    "for i in range(10):\n",
    "    d_classifs = classifiers[digit_indexes[i]].tolist()\n",
    "    digit_classifiers.append(d_classifs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### digit_signs: whether the given digit is treated as the positive or negative class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_signs = []\n",
    "for i in range(10):\n",
    "    d_sign = []\n",
    "    for pair in digit_classifiers[i]:\n",
    "        \n",
    "        if pair[0] == i :\n",
    "            d_sign.append(+1)\n",
    "        else:\n",
    "            d_sign.append(-1)\n",
    "    digit_signs.append(d_sign)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-class 1-vs-1 perceptron. \n",
    "\n",
    "We find that the algorithm converges after approximately 8-10 epochs, where by 'convergence' we refer to convergence on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelPerceptron(object):\n",
    "    \n",
    "    def __init__(self, X_train, y_train, X_test, y_test, kernel_type='p', d=5, epochs = 8):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.kernel_type = kernel_type\n",
    "        self.degree = d\n",
    "        self.epochs = epochs\n",
    "        \n",
    "        # Initalise number of classes, number of classifiers and batch size\n",
    "        self.C = 10\n",
    "        self.c = 45\n",
    "        self.batch_size = self.y_train.shape[0]  \n",
    "        self.test_size = self.y_test.shape[0]\n",
    "\n",
    "        # Compute the kernel matrix\n",
    "        if kernel_type == 'p':\n",
    "            self.K = efficient_poly_matrix(self.X_train, self.X_train, self.degree)\n",
    "            self.K_test = efficient_poly_matrix(self.X_train, self.X_test, self.degree)\n",
    "            \n",
    "        if kernel_type == 'g':\n",
    "            self.K = gaussian_matrix(self.X_train, self.X_train, self.degree)\n",
    "            self.K_test = gaussian_matrix(self.X_train, self.X_test, self.degree)\n",
    "            \n",
    "        # Initialise alphas\n",
    "        self.alphas = np.zeros(shape = (self.batch_size, self.c), dtype = np.float64)\n",
    "   \n",
    "        \n",
    "    def predicition(self, i, t='train'):\n",
    "       \n",
    "        # Compute the confidences for each digit for the given observation \n",
    "        if t == 'train':\n",
    "            y_hat = self.alphas.T @ self.K[:,i] \n",
    "        \n",
    "        elif t == 'test':\n",
    "            y_hat = self.alphas.T @ self.K_test[:,i] \n",
    "    \n",
    "        return y_hat\n",
    "    \n",
    "    \n",
    "    def train_single_pass(self):\n",
    "\n",
    "        errors = 0\n",
    "\n",
    "        # For each training example\n",
    "        for i in range(self.batch_size):\n",
    "\n",
    "            # True y value\n",
    "            y = self.y_train[i]\n",
    "            \n",
    "            # Get the indexes of classifiers\n",
    "            digit_ind = digit_indexes[int(y)]\n",
    "            # Digits which the classifiers look at\n",
    "            digit_classif = digit_classifiers[int(y)]\n",
    "            # Whether the classifers treats the digit as the positive or the negative class\n",
    "            digit_sign =digit_signs[int(y)]\n",
    "\n",
    "            # Predicted y values for each of the 45 classifiers\n",
    "            y_predictions = self.predicition(i, t='train')\n",
    "            \n",
    "            # Convert predictions to integers\n",
    "            y_int = np.zeros(shape=(1,45))\n",
    "            for j in range(len(y_predictions)):\n",
    "                \n",
    "                if y_predictions[j]>=0:\n",
    "                    # Predict the positive class\n",
    "                    y_int[:,j] = classifiers[j][0]\n",
    "                else:\n",
    "                    # Predict the negative class\n",
    "                    y_int[:,j] = classifiers[j][1]\n",
    "                    \n",
    "            \n",
    "            # Update the 9 relevant classifiers\n",
    "            y_preds = y_predictions[digit_ind]            \n",
    "            \n",
    "            for k in range(len(y_preds)):\n",
    "                \n",
    "                # Positive class\n",
    "                if digit_sign[k] == 1:\n",
    "                    # If incorrect:\n",
    "                    if y_preds[k]<=0:\n",
    "                        # Update alphas\n",
    "                        self.alphas[i, digit_ind[k]] +=1\n",
    "                     \n",
    "                # Negative class    \n",
    "                else:\n",
    "                    # If incorrect:\n",
    "                    if y_preds[k]>=0:\n",
    "                        # Update alphas\n",
    "                        self.alphas[i, digit_ind[k]] -=1            \n",
    "           \n",
    "            # Final prediction    \n",
    "            counts = np.bincount(y_int[0,:].astype(int))\n",
    "            y_final = np.argmax(counts)    \n",
    "            if y_final != y:\n",
    "                errors +=1\n",
    "                \n",
    "        # Divide by batch size, to make the error invariant to number of observations\n",
    "        return (errors/self.batch_size)*100  \n",
    "                \n",
    "               \n",
    "    def test(self):\n",
    "            \n",
    "        errors = 0\n",
    "\n",
    "        # For each training example\n",
    "        for i in range(self.test_size):\n",
    "\n",
    "            # True y value\n",
    "            y = self.y_test[i]\n",
    "\n",
    "            # Predicted y values for each of the 45 classifiers\n",
    "            y_predictions = self.predicition(i, t='test')\n",
    "            y_int = np.zeros(shape=(1,45))\n",
    "            \n",
    "            for j in range(len(y_predictions)):\n",
    "                \n",
    "                if y_predictions[j]>=0:\n",
    "                    # Predict the positive class\n",
    "                    y_int[:,j] = classifiers[j][0]\n",
    "                else:\n",
    "                    # Predict the negative class\n",
    "                    y_int[:,j] = classifiers[j][1]\n",
    "\n",
    "            # Final prediction    \n",
    "            counts = np.bincount(y_int[0,:].astype(int))\n",
    "            y_final = np.argmax(counts)    \n",
    "            \n",
    "            if y_final != y:\n",
    "                errors +=1\n",
    "                      \n",
    "        # Divide by batch size, to make the error invariant to number of observations\n",
    "        return (errors/self.test_size)*100  \n",
    "                \n",
    "    \n",
    "    def train(self):\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "        \n",
    "            error = self.train_single_pass()\n",
    "        \n",
    "        return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1t: 38.78853180000442\n",
      "Run: 2t: 46.427496799995424\n",
      "Run: 3t: 58.51736730002449\n",
      "Run: 4t: 50.21826880000299\n",
      "Run: 5t: 62.27371400000993\n",
      "Run: 6t: 57.97173299998394\n",
      "Run: 7t: 61.57353999998304\n",
      "Run: 8t: 66.8907240999979\n",
      "Run: 9t: 71.13364630000433\n",
      "Run: 10t: 54.26405440000235\n",
      "Run: 11t: 37.490868599998066\n",
      "Run: 12t: 36.099010999983875\n",
      "Run: 13t: 45.849452599999495\n",
      "Run: 14t: 35.1863735000079\n",
      "Run: 15t: 34.20488479998312\n",
      "Run: 16t: 29.49258029999328\n",
      "Run: 17t: 37.047727700002724\n",
      "Run: 18t: 47.630399599991506\n",
      "Run: 19t: 42.097494900022866\n",
      "Run: 20t: 49.90988270001253\n"
     ]
    }
   ],
   "source": [
    "times = []\n",
    "for i in range(20):\n",
    "    startTime = time.perf_counter()\n",
    "    \n",
    "    clf = KernelPerceptron(X_train, y_train, X_test, y_test, kernel_type='p', d=7, epochs=10)\n",
    "    train_error = clf.train()\n",
    "    test_error = clf.test()\n",
    "\n",
    "    t = time.perf_counter() - startTime\n",
    "    print(\"Run: \" + str(i+1) + \" t: \" + str(t))\n",
    "    times.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean computational time: 48.15338761000021+/-11.690515412047638 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean computational time: \" + str(np.mean(times)) +\"+/-\" + str(np.std(times)) + \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Basic Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial order: 1 Average % train error: 3.543291207313794\n",
      "Polynomial order: 2 Average % train error: 0.3085506856681903\n",
      "Polynomial order: 3 Average % train error: 0.08133906964237698\n",
      "Polynomial order: 4 Average % train error: 0.04907233127184728\n",
      "Polynomial order: 5 Average % train error: 0.043694541543425655\n",
      "Polynomial order: 6 Average % train error: 0.03562785695079323\n",
      "Polynomial order: 7 Average % train error: 0.03764452809895134\n"
     ]
    }
   ],
   "source": [
    "## 20 runs for d = {1,..,8}\n",
    "\n",
    "train_errors = []\n",
    "train_sd = []\n",
    "test_errors = []\n",
    "test_sd = []\n",
    "\n",
    "for poly_order in range(1,8):\n",
    "    \n",
    "    run_train_errors = []\n",
    "    run_test_errors = []\n",
    "    \n",
    "    for run in range(20):\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "        \n",
    "        clf = KernelPerceptron(X_train, y_train, X_test, y_test, kernel_type='p', d=poly_order, epochs=8)\n",
    "        train_error = clf.train()\n",
    "        test_error = clf.test()\n",
    "        run_train_errors.append(train_error)\n",
    "        run_test_errors.append(test_error)\n",
    "        \n",
    "    train_errors.append(np.mean(run_train_errors))\n",
    "    print(\"Polynomial order: \" + str(poly_order) + \" Average % train error: \"+ str(np.mean(run_train_errors)))\n",
    "    test_errors.append(np.mean(run_test_errors))\n",
    "    test_sd.append(np.std(run_test_errors))\n",
    "    train_sd.append(np.std(run_train_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a df to store the error results\n",
    "errors_df = pd.DataFrame()\n",
    "errors_df['d'] = np.array(range(1,8))\n",
    "errors_df['Train Error %'] = train_errors\n",
    "errors_df['+/- Train %'] = train_sd\n",
    "errors_df['Test Error %'] = test_errors\n",
    "errors_df['+/- Test %'] = test_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d</th>\n",
       "      <th>Train Error %</th>\n",
       "      <th>+/- Train %</th>\n",
       "      <th>Test Error %</th>\n",
       "      <th>+/- Test %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3.543291</td>\n",
       "      <td>0.177674</td>\n",
       "      <td>6.451613</td>\n",
       "      <td>0.737559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.308551</td>\n",
       "      <td>0.078218</td>\n",
       "      <td>3.706989</td>\n",
       "      <td>0.484013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.081339</td>\n",
       "      <td>0.044076</td>\n",
       "      <td>3.336022</td>\n",
       "      <td>0.388243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.049072</td>\n",
       "      <td>0.018666</td>\n",
       "      <td>3.282258</td>\n",
       "      <td>0.492889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.043695</td>\n",
       "      <td>0.021204</td>\n",
       "      <td>3.336022</td>\n",
       "      <td>0.418691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.035628</td>\n",
       "      <td>0.025957</td>\n",
       "      <td>3.413978</td>\n",
       "      <td>0.398539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.037645</td>\n",
       "      <td>0.025367</td>\n",
       "      <td>3.440860</td>\n",
       "      <td>0.327472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   d  Train Error %  +/- Train %  Test Error %  +/- Test %\n",
       "0  1       3.543291     0.177674      6.451613    0.737559\n",
       "1  2       0.308551     0.078218      3.706989    0.484013\n",
       "2  3       0.081339     0.044076      3.336022    0.388243\n",
       "3  4       0.049072     0.018666      3.282258    0.492889\n",
       "4  5       0.043695     0.021204      3.336022    0.418691\n",
       "5  6       0.035628     0.025957      3.413978    0.398539\n",
       "6  7       0.037645     0.025367      3.440860    0.327472"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to csv\n",
    "errors_df.to_csv('one-v-one-errors_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 0 Test Error: 2.956989247311828 d*:  4\n",
      "Run: 1 Test Error: 4.408602150537634 d*:  4\n",
      "Run: 2 Test Error: 5.43010752688172 d*:  3\n",
      "Run: 3 Test Error: 3.118279569892473 d*:  4\n",
      "Run: 4 Test Error: 3.4408602150537635 d*:  4\n",
      "Run: 5 Test Error: 3.2795698924731185 d*:  5\n",
      "Run: 6 Test Error: 4.354838709677419 d*:  3\n",
      "Run: 7 Test Error: 3.870967741935484 d*:  6\n",
      "Run: 8 Test Error: 3.2795698924731185 d*:  3\n",
      "Run: 9 Test Error: 2.849462365591398 d*:  3\n",
      "Run: 10 Test Error: 2.903225806451613 d*:  4\n",
      "Run: 11 Test Error: 3.225806451612903 d*:  5\n",
      "Run: 12 Test Error: 3.118279569892473 d*:  5\n",
      "Run: 13 Test Error: 3.225806451612903 d*:  5\n",
      "Run: 14 Test Error: 3.978494623655914 d*:  3\n",
      "Run: 15 Test Error: 3.4408602150537635 d*:  6\n",
      "Run: 16 Test Error: 2.903225806451613 d*:  6\n",
      "Run: 17 Test Error: 2.4731182795698925 d*:  3\n",
      "Run: 18 Test Error: 3.387096774193549 d*:  3\n",
      "Run: 19 Test Error: 3.225806451612903 d*:  4\n"
     ]
    }
   ],
   "source": [
    "d_stars = []\n",
    "test_errors = []\n",
    "\n",
    "for run in range(20):\n",
    "\n",
    "    # Split the data into 80% training, 20% test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "    \n",
    "    # Initialise\n",
    "    best_error = 500\n",
    "    best_d = 0\n",
    "\n",
    "    for d_ in range(1,8):\n",
    "       \n",
    "        error = 0 \n",
    "        \n",
    "        # Implement cross-validation\n",
    "        kfold = KFold(5, True, 1)\n",
    "\n",
    "        for train_index, test_index in kfold.split(X_train):\n",
    "            Xtrain, Xtest = X_train[train_index], X_train[test_index]\n",
    "            ytrain, ytest = y_train[train_index], y_train[test_index]\n",
    "            clf = KernelPerceptron(Xtrain, ytrain, Xtest, ytest, kernel_type='p', d=d_, epochs=8)\n",
    "            train_error = clf.train()\n",
    "            error += clf.test()\n",
    "        \n",
    "        if error/5 < best_error:\n",
    "            best_error = error/5\n",
    "            best_d = d_\n",
    "            \n",
    "    # Once all the polynomial orders considered, retrain on full 80% using d*\n",
    "    clf = KernelPerceptron(X_train, y_train, X_test, y_test, kernel_type='p', d=best_d, epochs=5)\n",
    "    train_error = clf.train()\n",
    "    test_error = clf.test()\n",
    "    print(\"Run: \" + str(run) + \" Test Error: \" + str(test_error) + \" d*:  \" + str(best_d))\n",
    "    test_errors.append(test_error)\n",
    "    d_stars.append(best_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean test error: 3.4435483870967745 +/- 0.659665588662744\n",
      "Mean d*: 4.15 +/- 1.061838029079765\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean test error: \" + str(np.mean(test_errors)) + \" +/- \" + str(np.std(test_errors)))\n",
    "print(\"Mean d*: \" + str(np.mean(d_stars)) + \" +/- \" + str(np.std(d_stars)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
