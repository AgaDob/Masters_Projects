{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics.pairwise import polynomial_kernel\n",
    "from numpy.linalg import inv, norm\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from numpy import mean\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data from csv\n",
    "Store the data as a numpy array. \\\n",
    "Shape of the full dataset: \n",
    "9298 observations (rows), 257 cols, where column 1 corresponds to the true label of the digit, while the cols 2:257 store greyscale values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import to df\n",
    "data_df = pd.read_csv(\"zipcombo2.csv\")\n",
    "\n",
    "# Convert to array to facilitate vectorization later\n",
    "data = data_df.to_numpy()\n",
    "X = data[:, 1:]\n",
    "y = data[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = []\n",
    "for i in range(20):\n",
    "    startTime = time.perf_counter()\n",
    "\n",
    "    clf = SVC(C = c_, gamma='auto')\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_error = 100 - clf.score(X_train, y_train)*100 # the function 'score' gives accuracy: 1 - test_error\n",
    "    test_error = 100 - clf.score(X_test, y_test)*100 # the function 'score' gives accuracy: 1 - test_error\n",
    "\n",
    "    t = time.perf_counter() - startTime\n",
    "    print(\"Run: \" + str(i+1) + \"t: \" + str(t))\n",
    "    times.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean computational time: 14.084167625001282+/-1.043109053152576 seconds.\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean computational time: \" + str(np.mean(times)) +\"+/-\" + str(np.std(times)) + \" seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with different parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start our model selection by selecting whether we will use the polynomial kernel or the gaussian kernel. To make this decision, we train the model on both, gaussian and polynomial kernel for a few different parameters of gamma and c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 0 Train Error 83.51707448238774 Test Error: 82.41935483870968\n",
      "Run: 1 Train Error 83.51707448238774 Test Error: 82.41935483870968\n",
      "Run: 2 Train Error 83.51707448238774 Test Error: 82.41935483870968\n",
      "Run: 3 Train Error 5.041677870395262 Test Error: 6.075268817204304\n"
     ]
    }
   ],
   "source": [
    "## Code used to compare gaussian and polynomial kernel\n",
    "\n",
    "### RBF Kernel\n",
    "train_errs = []\n",
    "test_errs = []\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "trial_c = [0.000001, 0.00001, 0.001, 0.1 ]\n",
    "\n",
    "for i, c_ in enumerate(trial_c):\n",
    "    \n",
    "    clf = SVC(C = c_, gamma='auto', kernel = 'rbf')\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_error = 100 - clf.score(X_train, y_train)*100 # the function 'score' gives accuracy: 1 - test_error\n",
    "    test_error = 100 - clf.score(X_test, y_test)*100 # the function 'score' gives accuracy: 1 - test_error\n",
    "    train_errs.append(train_error)\n",
    "    test_errs.append(test_error)\n",
    "    print(\"Run: \" + str(i) + \" Train Error \" + str(train_error)+ \" Test Error: \" + str(test_error))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 0 Train Error 83.14062920139823 Test Error: 83.9247311827957\n",
      "Run: 1 Train Error 83.14062920139823 Test Error: 83.9247311827957\n",
      "Run: 2 Train Error 83.14062920139823 Test Error: 83.9247311827957\n",
      "Run: 3 Train Error 5.754235009411133 Test Error: 6.72043010752688\n"
     ]
    }
   ],
   "source": [
    "### Polynomial Kernel\n",
    "train_errs = []\n",
    "test_errs = []\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "trial_c = [0.000001, 0.00001, 0.001, 0.1 ]\n",
    "\n",
    "for i, c_ in enumerate(trial_c):\n",
    "    \n",
    "    clf = SVC(C = c_, gamma='auto', kernel = 'poly')\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_error = 100 - clf.score(X_train, y_train)*100 # the function 'score' gives accuracy: 1 - test_error\n",
    "    test_error = 100 - clf.score(X_test, y_test)*100 # the function 'score' gives accuracy: 1 - test_error\n",
    "    train_errs.append(train_error)\n",
    "    test_errs.append(test_error)\n",
    "    print(\"Run: \" + str(i) + \" Train Error \" + str(train_error)+ \" Test Error: \" + str(test_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code used to explore heuristic ranges of c\n",
    "\n",
    "train_errs = []\n",
    "test_errs = []\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "trial_c = [0.0001, 0.001, 0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "for i, c_ in enumerate(trial_c):\n",
    "    \n",
    "    clf = SVC(C = c_, gamma=0.1, kernel = 'rbf')\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_error = 100 - clf.score(X_train, y_train)*100 # the function 'score' gives accuracy: 1 - test_error\n",
    "    test_error = 100 - clf.score(X_test, y_test)*100 # the function 'score' gives accuracy: 1 - test_error\n",
    "    train_errs.append(train_error)\n",
    "    test_errs.append(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[82.95698924731182,\n",
       " 82.95698924731182,\n",
       " 24.408602150537632,\n",
       " 6.344086021505376,\n",
       " 3.225806451612897,\n",
       " 2.4731182795699027,\n",
       " 2.4731182795699027]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 0 Train Error 4.127453616563599 Test Error: 5.430107526881727\n",
      "Run: 1 Train Error 1.1158913686474818 Test Error: 3.4408602150537604\n",
      "Run: 2 Train Error 0.026888948642110222 Test Error: 2.4193548387096797\n",
      "Run: 3 Train Error 0.013444474321062216 Test Error: 52.47311827956989\n",
      "Run: 4 Train Error 0.0 Test Error: 75.75268817204301\n",
      "Run: 5 Train Error 0.0 Test Error: 82.41935483870968\n",
      "Run: 6 Train Error 0.0 Test Error: 82.41935483870968\n"
     ]
    }
   ],
   "source": [
    "## Code used to explore heuristic ranges of gamma\n",
    "\n",
    "train_errs = []\n",
    "test_errs = []\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "trial_c = [0.0001, 0.001, 0.01, 0.1, 1, 10, 10^3]\n",
    "\n",
    "for i, c_ in enumerate(trial_c):\n",
    "    \n",
    "    clf = SVC(C = 10, gamma=c_)\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_error = 100 - clf.score(X_train, y_train)*100 # the function 'score' gives accuracy: 1 - test_error\n",
    "    test_error = 100 - clf.score(X_test, y_test)*100 # the function 'score' gives accuracy: 1 - test_error\n",
    "    train_errs.append(train_error)\n",
    "    test_errs.append(test_error)\n",
    "    \n",
    "    print(\"Run: \" + str(i) + \" Train Error \" + str(train_error) + \" Test Error: \" + str(test_error))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 0 gamma: 0.001 Train Error 1.3847808550685698 Test Error: 2.741935483870975\n",
      "Run: 1 gamma: 0.005 Train Error 0.026888948642110222 Test Error: 2.1505376344086073\n",
      "Run: 2 gamma: 0.01 Train Error 0.0 Test Error: 1.8817204301075208\n",
      "Run: 3 gamma: 0.025 Train Error 0.0 Test Error: 3.0645161290322562\n",
      "Run: 4 gamma: 0.05 Train Error 0.0 Test Error: 15.752688172043008\n"
     ]
    }
   ],
   "source": [
    "## Narrowing further the range of gamma\n",
    "\n",
    "train_errs = []\n",
    "test_errs = []\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "trial_c = [ 0.001, 0.005, 0.01, 0.025, 0.05]\n",
    "\n",
    "for i, c_ in enumerate(trial_c):\n",
    "    \n",
    "    clf = SVC(C = 10, gamma=c_)\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_error = 100 - clf.score(X_train, y_train)*100 # the function 'score' gives accuracy: 1 - test_error\n",
    "    test_error = 100 - clf.score(X_test, y_test)*100 # the function 'score' gives accuracy: 1 - test_error\n",
    "    train_errs.append(train_error)\n",
    "    test_errs.append(test_error)\n",
    "    \n",
    "    print(\"Run: \" + str(i) + \" gamma: \"+ str(c_) + \" Train Error \" + str(train_error) + \" Test Error: \" + str(test_error))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 0 gamma: 0.009 Train Error 0.026888948642110222 Test Error: 1.7204301075268802\n",
      "Run: 1 gamma: 0.01 Train Error 0.026888948642110222 Test Error: 1.827956989247312\n",
      "Run: 2 gamma: 0.011 Train Error 0.026888948642110222 Test Error: 1.774193548387089\n",
      "Run: 3 gamma: 0.012 Train Error 0.026888948642110222 Test Error: 1.774193548387089\n",
      "Run: 4 gamma: 0.013 Train Error 0.026888948642110222 Test Error: 1.8817204301075208\n",
      "Run: 5 gamma: 0.014 Train Error 0.026888948642110222 Test Error: 1.9354838709677438\n",
      "Run: 6 gamma: 0.015 Train Error 0.026888948642110222 Test Error: 2.0430107526881613\n",
      "Run: 7 gamma: 0.017 Train Error 0.026888948642110222 Test Error: 2.0967741935483843\n",
      "Run: 8 gamma: 0.018 Train Error 0.026888948642110222 Test Error: 2.0967741935483843\n"
     ]
    }
   ],
   "source": [
    "## Picking the optimum gamma value\n",
    "\n",
    "train_errs = []\n",
    "test_errs = []\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "trial_c = [0.009, 0.01, 0.011, 0.012, 0.013, 0.014, 0.015, 0.017, 0.018]\n",
    "\n",
    "for i, c_ in enumerate(trial_c):\n",
    "    \n",
    "    clf = SVC(C = 10, gamma=c_)\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_error = 100 - clf.score(X_train, y_train)*100 # the function 'score' gives accuracy: 1 - test_error\n",
    "    test_error = 100 - clf.score(X_test, y_test)*100 # the function 'score' gives accuracy: 1 - test_error\n",
    "    train_errs.append(train_error)\n",
    "    test_errs.append(test_error)\n",
    "    \n",
    "    print(\"Run: \" + str(i) + \" gamma: \"+ str(c_) + \" Train Error \" + str(train_error) + \" Test Error: \" + str(test_error))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 0 c: 1000 Train Error 0.0 Test Error: 2.0967741935483843\n",
      "Run: 1 c: 10000 Train Error 0.0 Test Error: 2.0967741935483843\n",
      "Run: 2 c: 10000000 Train Error 0.0 Test Error: 2.0967741935483843\n",
      "Run: 3 c: 1000000000000000 Train Error 0.0 Test Error: 2.0967741935483843\n"
     ]
    }
   ],
   "source": [
    "## Code used to explore heuristic ranges of c\n",
    "\n",
    "train_errs = []\n",
    "test_errs = []\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "trial_c = [1000, 10**4,10**7, 10**15]\n",
    "\n",
    "for i, c_ in enumerate(trial_c):\n",
    "    \n",
    "    clf = SVC(C = c_, gamma=0.01)\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_error = 100 - clf.score(X_train, y_train)*100 # the function 'score' gives accuracy: 1 - test_error\n",
    "    test_error = 100 - clf.score(X_test, y_test)*100 # the function 'score' gives accuracy: 1 - test_error\n",
    "    train_errs.append(train_error)\n",
    "    test_errs.append(test_error)\n",
    "    \n",
    "    print(\"Run: \" + str(i) + \" c: \"+ str(c_) + \" Train Error \" + str(train_error) + \" Test Error: \" + str(test_error))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 0 c: 10 gamma : 0.009 Train Error 0.026888948642110222 Test Error: 2.6344086021505433\n",
      "Run: 0 c: 10 gamma : 0.01 Train Error 0.026888948642110222 Test Error: 2.6344086021505433\n",
      "Run: 0 c: 10 gamma : 0.011 Train Error 0.026888948642110222 Test Error: 2.6344086021505433\n",
      "Run: 1 c: 100 gamma : 0.009 Train Error 0.013444474321062216 Test Error: 2.6344086021505433\n",
      "Run: 1 c: 100 gamma : 0.01 Train Error 0.013444474321062216 Test Error: 2.6344086021505433\n",
      "Run: 1 c: 100 gamma : 0.011 Train Error 0.013444474321062216 Test Error: 2.6344086021505433\n",
      "Run: 2 c: 1000 gamma : 0.009 Train Error 0.0 Test Error: 2.688172043010752\n",
      "Run: 2 c: 1000 gamma : 0.01 Train Error 0.0 Test Error: 2.688172043010752\n",
      "Run: 2 c: 1000 gamma : 0.011 Train Error 0.0 Test Error: 2.688172043010752\n"
     ]
    }
   ],
   "source": [
    "## Rough grid search\n",
    "\n",
    "train_errs = []\n",
    "test_errs = []\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "trial_c = [10, 100, 1000]\n",
    "trial_gamma = [0.009, 0.01, 0.011]\n",
    "\n",
    "for i, c_ in enumerate(trial_c):\n",
    "    for gamma_ in trial_gamma:\n",
    "        clf = SVC(C = c_, gamma = gamma_)\n",
    "        clf.fit(X_train, y_train)\n",
    "        train_error = 100 - clf.score(X_train, y_train)*100 # the function 'score' gives accuracy: 1 - test_error\n",
    "        test_error = 100 - clf.score(X_test, y_test)*100 # the function 'score' gives accuracy: 1 - test_error\n",
    "        train_errs.append(train_error)\n",
    "        test_errs.append(test_error)\n",
    "\n",
    "        print(\"Run: \" + str(i) + \" c: \"+ str(c_) + \" gamma : \" + str(gamma_) + \" Train Error \" + str(train_error) + \" Test Error: \" + str(test_error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hence we choose a gaussian kernel with gamma = 0.01 and iterate over the c-values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Basic Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### using gamma = 0.017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-value: 1 Average % train error: 0.15595590212422863\n",
      "C-value: 10 Average % train error: 0.02218338262974271\n",
      "C-value: 20 Average % train error: 0.010755579456849773\n",
      "C-value: 30 Average % train error: 0.010083355740796662\n",
      "C-value: 40 Average % train error: 0.010755579456849773\n",
      "C-value: 50 Average % train error: 0.010755579456849773\n",
      "C-value: 60 Average % train error: 0.010755579456849773\n",
      "C-value: 70 Average % train error: 0.008738908308690441\n",
      "C-value: 80 Average % train error: 0.008738908308690441\n"
     ]
    }
   ],
   "source": [
    "## 20 runs for d = {1,..,8}\n",
    "\n",
    "train_errors = []\n",
    "train_sd = []\n",
    "test_errors = []\n",
    "test_sd = []\n",
    "\n",
    "for c_ in [1,10,20,30,40,50,60,70,80]:\n",
    "    \n",
    "    run_train_errors = []\n",
    "    run_test_errors = []\n",
    "    \n",
    "    for run in range(20):\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "        \n",
    "        clf = SVC(C = c_, gamma = 0.017)\n",
    "        clf.fit(X_train, y_train)\n",
    "        train_error = 100 - clf.score(X_train, y_train)*100 # the function 'score' gives accuracy: 1 - test_error\n",
    "        test_error = 100 - clf.score(X_test, y_test)*100 # the function 'score' gives accuracy: 1 - test_error\n",
    "\n",
    "        run_train_errors.append(train_error)\n",
    "        run_test_errors.append(test_error)\n",
    "        \n",
    "    train_errors.append(np.mean(run_train_errors))\n",
    "    print(\"C-value: \" + str(c_) + \" Average % train error: \"+ str(np.mean(run_train_errors)))\n",
    "    test_errors.append(np.mean(run_test_errors))\n",
    "    test_sd.append(np.std(run_test_errors))\n",
    "    train_sd.append(np.std(run_train_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a df to store the error results\n",
    "errors_df = pd.DataFrame()\n",
    "errors_df['d'] = [1,10,20,30,40,50,60,70,80]\n",
    "errors_df['Train Error %'] = train_errors\n",
    "errors_df['+/- Train %'] = train_sd\n",
    "errors_df['Test Error %'] = test_errors\n",
    "errors_df['+/- Test %'] = test_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d</th>\n",
       "      <th>Train Error %</th>\n",
       "      <th>+/- Train %</th>\n",
       "      <th>Test Error %</th>\n",
       "      <th>+/- Test %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.155956</td>\n",
       "      <td>0.030183</td>\n",
       "      <td>2.497312</td>\n",
       "      <td>0.269072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.022183</td>\n",
       "      <td>0.007694</td>\n",
       "      <td>2.209677</td>\n",
       "      <td>0.241577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>0.010756</td>\n",
       "      <td>0.005378</td>\n",
       "      <td>2.376344</td>\n",
       "      <td>0.356059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>0.010083</td>\n",
       "      <td>0.005822</td>\n",
       "      <td>2.276882</td>\n",
       "      <td>0.368299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>0.010756</td>\n",
       "      <td>0.005378</td>\n",
       "      <td>2.370968</td>\n",
       "      <td>0.304559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>0.010756</td>\n",
       "      <td>0.005378</td>\n",
       "      <td>2.311828</td>\n",
       "      <td>0.327913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>60</td>\n",
       "      <td>0.010756</td>\n",
       "      <td>0.005378</td>\n",
       "      <td>2.395161</td>\n",
       "      <td>0.292245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>70</td>\n",
       "      <td>0.008739</td>\n",
       "      <td>0.006413</td>\n",
       "      <td>2.241935</td>\n",
       "      <td>0.286565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>80</td>\n",
       "      <td>0.008739</td>\n",
       "      <td>0.006413</td>\n",
       "      <td>2.486559</td>\n",
       "      <td>0.260003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    d  Train Error %  +/- Train %  Test Error %  +/- Test %\n",
       "0   1       0.155956     0.030183      2.497312    0.269072\n",
       "1  10       0.022183     0.007694      2.209677    0.241577\n",
       "2  20       0.010756     0.005378      2.376344    0.356059\n",
       "3  30       0.010083     0.005822      2.276882    0.368299\n",
       "4  40       0.010756     0.005378      2.370968    0.304559\n",
       "5  50       0.010756     0.005378      2.311828    0.327913\n",
       "6  60       0.010756     0.005378      2.395161    0.292245\n",
       "7  70       0.008739     0.006413      2.241935    0.286565\n",
       "8  80       0.008739     0.006413      2.486559    0.260003"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to csv\n",
    "errors_df.to_csv('svd_basic_errors_df.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 0 Test Error: 2.0430107526881613 d*:  10\n",
      "Run: 1 Test Error: 2.8494623655913927 d*:  10\n",
      "Run: 2 Test Error: 1.6666666666666714 d*:  10\n",
      "Run: 3 Test Error: 1.6666666666666714 d*:  10\n",
      "Run: 4 Test Error: 2.0430107526881613 d*:  30\n",
      "Run: 5 Test Error: 2.6344086021505433 d*:  10\n",
      "Run: 6 Test Error: 2.204301075268816 d*:  10\n",
      "Run: 7 Test Error: 2.4731182795699027 d*:  10\n",
      "Run: 8 Test Error: 2.204301075268816 d*:  10\n",
      "Run: 9 Test Error: 1.8817204301075208 d*:  10\n",
      "Run: 10 Test Error: 2.4193548387096797 d*:  10\n",
      "Run: 11 Test Error: 2.4731182795699027 d*:  10\n",
      "Run: 12 Test Error: 2.311827956989248 d*:  10\n",
      "Run: 13 Test Error: 1.8817204301075208 d*:  10\n",
      "Run: 14 Test Error: 2.0967741935483843 d*:  10\n",
      "Run: 15 Test Error: 2.204301075268816 d*:  10\n",
      "Run: 16 Test Error: 1.827956989247312 d*:  10\n",
      "Run: 17 Test Error: 2.258064516129039 d*:  10\n",
      "Run: 18 Test Error: 1.827956989247312 d*:  10\n",
      "Run: 19 Test Error: 2.5806451612903203 d*:  50\n"
     ]
    }
   ],
   "source": [
    "d_stars = []\n",
    "test_errors = []\n",
    "\n",
    "for run in range(20):\n",
    "\n",
    "    # Split the data into 80% training, 20% test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "    \n",
    "    # Initialise\n",
    "    best_error = 500\n",
    "    best_d = 0\n",
    "\n",
    "    for d_ in [1,10,30,50,70,100]:\n",
    "       \n",
    "        error = 0 \n",
    "        \n",
    "        # Implement cross-validation\n",
    "        kfold = KFold(5, True, 1)\n",
    "\n",
    "        for train_index, test_index in kfold.split(X_train):\n",
    "            Xtrain, Xtest = X_train[train_index], X_train[test_index]\n",
    "            ytrain, ytest = y_train[train_index], y_train[test_index]\n",
    "            clf = SVC(C = d_, gamma = 0.017)\n",
    "            clf.fit(Xtrain, ytrain)\n",
    "            train_error = 100 - clf.score(Xtrain, ytrain)*100 # the function 'score' gives accuracy: 1 - test_error\n",
    "            test_error = 100 - clf.score(Xtest, ytest)*100 # the function 'score' gives accuracy: 1 - test_error\n",
    "\n",
    "            error += test_error\n",
    "        \n",
    "        if error/5 < best_error:\n",
    "            best_error = error/5\n",
    "            best_d = d_\n",
    "            \n",
    "    # Once all the polynomial orders considered, retrain on full 80% using d*\n",
    "    clf = SVC(C = best_d, gamma = 0.01)\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_error = 100 - clf.score(X_train, y_train)*100 # the function 'score' gives accuracy: 1 - test_error\n",
    "    test_error = 100 - clf.score(X_test, y_test)*100 # the function 'score' gives accuracy: 1 - test_error\n",
    "\n",
    "    print(\"Run: \" + str(run) + \" Test Error: \" + str(test_error) + \" d*:  \" + str(best_d))\n",
    "    test_errors.append(test_error)\n",
    "    d_stars.append(best_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean test error: 2.1774193548387095 +/- 0.32145862212638276\n",
      "Mean d*: 13.0 +/- 9.539392014169456\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean test error: \" + str(np.mean(test_errors)) + \" +/- \" + str(np.std(test_errors)))\n",
    "print(\"Mean d*: \" + str(np.mean(d_stars)) + \" +/- \" + str(np.std(d_stars)))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
