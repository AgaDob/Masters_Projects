{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Demo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Tw945AuED_9h"
      },
      "source": [
        "# Contents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pZh64VtiEGaq"
      },
      "source": [
        "\n",
        "\n",
        "1. Imports\n",
        "    - import packages <br>\n",
        "2. Data\n",
        "    - define directory path<br>\n",
        "    - read raw data csv files into pandas for both original and reduced datasets from directory<br>\n",
        "    - create summary statistic table with length of training and test sets and number of occupation labels<br>\n",
        "    - create occupation frequency chart for original data set<br>\n",
        "3. Utility Functions\n",
        "    - define some utility functions<br>\n",
        "4. Graphs\n",
        "    - clean original test dataset by removing words that are not included in the training vocabulary<br>\n",
        "    - build feature vectors and one hot labels for original test data<br>\n",
        "    - load feature vectors, one hot labels and adjacency matrix for original training data from directory<br>\n",
        "5. Model\n",
        "    - define intialisation functions<br>\n",
        "    - define layers<br>\n",
        "    - define training metrics<br>\n",
        "    - define model<br>\n",
        "6. Prediction\n",
        "    - load GCN trained with original dataset with gender indicators<br>\n",
        "    - predict occupation labels for original dataset<br>\n",
        "7. Analyses\n",
        "    - calculate TPR, TPR gender gap and $\\pi_{g,y}$ for the gender \"female\"<br>\n",
        "    - plot for $\\text{Gap}_{female,y}$ and $\\pi_{female,y}$ and compute correlation <br>\n",
        "    - compute gender imbalance and compounding factor<br>\n",
        "    - load predictions on scrubbed test dataset<br>\n",
        "    - TPR, TPR gender gap and correlation between TPR gender gap and $\\pi_{female,y}$ on scrubbed dataset<br>\n",
        "    - plot of $\\text{Gap}_{female,y}$ and $\\pi_{female,y}$ for original compared to scrubbed test dataset<br>\n",
        "    - proportion of compounding factors pulled towards 1 after scrubbing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8GjtmTumIrHZ"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdHQ5TDoEjvD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e9b6ce7-2bcd-4a7b-81e6-49ff6a2f1c4b"
      },
      "source": [
        "import pickle\n",
        "import csv\n",
        "import random\n",
        "from sklearn import preprocessing\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "from nltk.corpus import stopwords\n",
        "import nltk\n",
        "from nltk.wsd import lesk\n",
        "from nltk.corpus import wordnet as wn\n",
        "import sys\n",
        "import pickle as pkl\n",
        "import networkx as nx\n",
        "import scipy.sparse as sp\n",
        "from scipy.sparse.linalg.eigen.arpack import eigsh\n",
        "import re\n",
        "import os\n",
        "from math import log\n",
        "from sklearn import svm\n",
        "from nltk.corpus import wordnet as wn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.spatial.distance import cosine\n",
        "# colab will be updated to tensorflow 2.x soon\n",
        "%tensorflow_version 1.x \n",
        "import tensorflow as tf\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import time\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "import timeit"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "h0GoUYmVI8BS"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5HR3dKjTJDXn"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ldG0EZNUzUvW"
      },
      "source": [
        "Choose whether you would like to perform data cleaning which takes an additional 8 mins (True) or load cleaned data to save time (False)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7gPdgWIlzhHj",
        "colab": {}
      },
      "source": [
        "clean = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "S1vn-G-5J18v"
      },
      "source": [
        "Please define the path to directory where data is saved below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KZZZ5IFQJ_SF",
        "colab": {}
      },
      "source": [
        "alldatapath = './all data'\n",
        "testdatapath = './test data'\n",
        "trainedmodelpath = './trained model'\n",
        "traininggraph = './training graph'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-p_TzrF9Ju57",
        "colab": {}
      },
      "source": [
        "base_set = pd.read_csv('{}/preprocessed.csv'.format(alldatapath)) # complete dataset\n",
        "base_set_1000 = pd.read_csv('{}/preprocessed_1000.csv'.format(alldatapath)) # complete dataset\n",
        "occupation_dict = np.array(pd.read_csv('{}/occupation.csv'.format(alldatapath), header=None)) # occupations + coded occupations\n",
        "g = np.array(base_set.iloc[round(0.7 * len(base_set)):, base_set.columns.get_loc('gender')]) # gender labels for test set\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "K2liOz5iJb5Z"
      },
      "source": [
        "## Summary Statistics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H2ChK7H0MNYZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "e36fe017-92bf-4a8d-fb82-0588c9dbd0eb"
      },
      "source": [
        "summary = pd.DataFrame({'train size': [round(0.7 * len(base_set)), round(0.7 * len(base_set_1000))],\n",
        "                        'test size': [len(base_set)-round(0.7 * len(base_set)), len(base_set_1000)-round(0.7 * len(base_set_1000))],\n",
        "                        'no. labels': [len(np.unique(base_set['label'])),len(np.unique(base_set_1000['label']))]})\n",
        "summary.index= ['original', 'reduced']\n",
        "display(summary)                                   "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train size</th>\n",
              "      <th>test size</th>\n",
              "      <th>no. labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>original</th>\n",
              "      <td>68459</td>\n",
              "      <td>29339</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reduced</th>\n",
              "      <td>65475</td>\n",
              "      <td>28061</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          train size  test size  no. labels\n",
              "original       68459      29339          28\n",
              "reduced        65475      28061          19"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HDXkgIIWJnso"
      },
      "source": [
        "## Occupation Frequencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bCjKPSJWTE-i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "99f7a432-fa0f-4f89-8f7a-73695f870229"
      },
      "source": [
        "y_total = np.array(base_set['label']) # all occupation labels\n",
        "g_total = np.array(base_set['gender']) # all gender labels\n",
        "\n",
        "lbl, cnts = np.unique(y_total, return_counts=True)\n",
        "cnts_sorted, lbl_sorted = zip(*sorted(list(zip(cnts, lbl)), reverse=True))\n",
        "new_dict = dict(occupation_dict)\n",
        "plot_labels = [new_dict[label] for label in lbl_sorted]\n",
        "\n",
        "f = [i for i, x in enumerate(np.array(g_total)) if np.array(g_total)[i]=='F']\n",
        "y_total_f = y_total[f]\n",
        "\n",
        "lbl_f, cnts_f = np.unique(y_total_f, return_counts=True)  \n",
        "cnts_sorted_f_orig, lbl_sorted_f_orig = zip(*sorted(list(zip(cnts_f, lbl_f)), reverse=True))\n",
        "new_dict = dict(occupation_dict)\n",
        "plot_labels_f_orig = [new_dict[label] for label in lbl_sorted_f_orig]\n",
        "\n",
        "zipped = list(zip(plot_labels_f_orig, cnts_sorted_f_orig))\n",
        "zipped_ordered = []\n",
        "for i in range(len(plot_labels)):\n",
        "  for j in range(len(plot_labels)):\n",
        "    if plot_labels[i] in zipped[j]:\n",
        "        zipped_ordered.append(zipped[j])\n",
        "plot_labels_f, cnts_sorted_f = zip(*zipped_ordered)\n",
        "\n",
        "f, (ax, ax2) = plt.subplots(2, 1, sharex=True)\n",
        "\n",
        "# plot the same data on both axes\n",
        "total = ax.bar(range(len(plot_labels)), cnts_sorted, label = 'total')\n",
        "female = ax.bar(range(len(plot_labels_f)), cnts_sorted_f, color='r', label = 'female')\n",
        "ax2.bar(range(len(plot_labels)), cnts_sorted)\n",
        "ax2.bar(range(len(plot_labels_f)), cnts_sorted_f, color='r')\n",
        "\n",
        "# zoom-in / limit the view to different portions of the data\n",
        "ax.set_ylim(15000, 36000)  # outliers only\n",
        "ax2.set_ylim(0, 10000)  # most of the data\n",
        "\n",
        "# hide the spines between ax and ax2\n",
        "plt.xticks(range(len(plot_labels)), plot_labels, rotation=90)\n",
        "ax.spines['bottom'].set_visible(False)\n",
        "ax.xaxis.tick_top()\n",
        "ax2.spines['top'].set_visible(False)\n",
        "\n",
        "d = .015  \n",
        "kwargs = dict(transform=ax.transAxes, color='k', clip_on=False)\n",
        "ax.plot((-d, +d), (-d, +d), **kwargs)        # top-left diagonal\n",
        "ax.plot((1 - d, 1 + d), (-d, +d), **kwargs)  # top-right diagonal\n",
        "\n",
        "kwargs.update(transform=ax2.transAxes)  # switch to the bottom axes\n",
        "ax2.plot((-d, +d), (1 - d, 1 + d), **kwargs)  # bottom-left diagonal\n",
        "ax2.plot((1 - d, 1 + d), (1 - d, 1 + d), **kwargs)  # bottom-right diagonal\n",
        "\n",
        "ax.legend(loc ='upper right')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ouWBJU1vjZtP"
      },
      "source": [
        "# Utility Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oaOBGnysjcOk",
        "colab": {}
      },
      "source": [
        "def parse_index_file(filename):\n",
        "    \"\"\"Parse index file.\"\"\"\n",
        "    index = []\n",
        "    for line in open(filename):\n",
        "        index.append(int(line.strip()))\n",
        "    return index\n",
        "\n",
        "\n",
        "def sample_mask(idx, l):\n",
        "    \"\"\"Create mask.\"\"\"\n",
        "    mask = np.zeros(l)\n",
        "    mask[idx] = 1\n",
        "    return np.array(mask, dtype=np.bool)\n",
        "\n",
        "def load_corpus(test_data_str,train_data_str):\n",
        "    \"\"\"\n",
        "    Loads input corpus from gcn/data directory\n",
        "    ind.dataset_str.x => the feature vectors of the training docs as scipy.sparse.csr.csr_matrix object;\n",
        "    ind.dataset_str.tx => the feature vectors of the test docs as scipy.sparse.csr.csr_matrix object;\n",
        "    ind.dataset_str.allx => the feature vectors of both labeled and unlabeled training docs/words\n",
        "        (a superset of ind.dataset_str.x) as scipy.sparse.csr.csr_matrix object;\n",
        "    ind.dataset_str.y => the one-hot labels of the labeled training docs as numpy.ndarray object;\n",
        "    ind.dataset_str.ty => the one-hot labels of the test docs as numpy.ndarray object;\n",
        "    ind.dataset_str.ally => the labels for instances in ind.dataset_str.allx as numpy.ndarray object;\n",
        "    ind.dataset_str.adj => adjacency matrix of word/doc nodes as scipy.sparse.csr.csr_matrix object;\n",
        "    ind.dataset_str.train.index => the indices of training docs in original doc list.\n",
        "    All objects above must be saved using python pickle module.\n",
        "    :param dataset_str: Dataset name\n",
        "    :return: All data input files loaded (as well the training/test data).\n",
        "    \"\"\"\n",
        "\n",
        "    train_names = ['x', 'y']  # add in 'graph'\n",
        "    test_names = ['tx','ty']\n",
        "    train_names2 = ['allx', 'ally', 'adj']\n",
        "    objects = []\n",
        "    for i in range(len(train_names)):\n",
        "        with open(\"{}/ind.{}.{}\".format(traininggraph, train_data_str, train_names[i]), 'rb') as f:\n",
        "            if sys.version_info > (3, 0):\n",
        "                objects.append(pkl.load(f, encoding='latin1'))\n",
        "            else:\n",
        "                objects.append(pkl.load(f))\n",
        "    for i in range(len(test_names)):\n",
        "        with open(\"{}/ind.{}.{}\".format(testdatapath, test_data_str, test_names[i]), 'rb') as f:\n",
        "            if sys.version_info > (3, 0):\n",
        "                objects.append(pkl.load(f, encoding='latin1'))\n",
        "            else:\n",
        "                objects.append(pkl.load(f))\n",
        "    for i in range(len(train_names2)):\n",
        "      with open(\"{}/ind.{}.{}\".format(traininggraph, train_data_str, train_names2[i]), 'rb') as f:\n",
        "          if sys.version_info > (3, 0):\n",
        "              objects.append(pkl.load(f, encoding='latin1'))\n",
        "          else:\n",
        "              objects.append(pkl.load(f))\n",
        "\n",
        "    x, y, tx, ty, allx, ally, adj = tuple(objects)\n",
        "    print(x.shape, y.shape, tx.shape, ty.shape, allx.shape, ally.shape)\n",
        "\n",
        "    features = sp.vstack((allx, tx)).tolil()\n",
        "    labels = np.vstack((ally, ty))\n",
        "    print(len(labels))\n",
        "\n",
        "    train_idx_orig = parse_index_file(\"{}/{}.train.index\".format(traininggraph,train_data_str))\n",
        "    train_size = len(train_idx_orig)\n",
        "\n",
        "    val_size = train_size - x.shape[0]\n",
        "    test_size = tx.shape[0]\n",
        "\n",
        "    idx_train = range(len(y))\n",
        "    idx_val = range(len(y), len(y) + val_size)\n",
        "    idx_test = range(allx.shape[0], allx.shape[0] + test_size)\n",
        "\n",
        "    train_mask = sample_mask(idx_train, labels.shape[0])\n",
        "    val_mask = sample_mask(idx_val, labels.shape[0])\n",
        "    test_mask = sample_mask(idx_test, labels.shape[0])\n",
        "\n",
        "    y_train = np.zeros(labels.shape)\n",
        "    y_val = np.zeros(labels.shape)\n",
        "    y_test = np.zeros(labels.shape)\n",
        "    y_train[train_mask, :] = labels[train_mask, :]\n",
        "    y_val[val_mask, :] = labels[val_mask, :]\n",
        "    y_test[test_mask, :] = labels[test_mask, :]\n",
        "\n",
        "    adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
        "\n",
        "    return adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask, train_size, test_size\n",
        "\n",
        "\n",
        "def sparse_to_tuple(sparse_mx):\n",
        "    \"\"\"Convert sparse matrix to tuple representation.\"\"\"\n",
        "    def to_tuple(mx):\n",
        "        if not sp.isspmatrix_coo(mx):\n",
        "            mx = mx.tocoo()\n",
        "        coords = np.vstack((mx.row, mx.col)).transpose()\n",
        "        values = mx.data\n",
        "        shape = mx.shape\n",
        "        return coords, values, shape\n",
        "\n",
        "    if isinstance(sparse_mx, list):\n",
        "        for i in range(len(sparse_mx)):\n",
        "            sparse_mx[i] = to_tuple(sparse_mx[i])\n",
        "    else:\n",
        "        sparse_mx = to_tuple(sparse_mx)\n",
        "\n",
        "    return sparse_mx\n",
        "\n",
        "\n",
        "def preprocess_features(features):\n",
        "    \"\"\"Row-normalize feature matrix and convert to tuple representation\"\"\"\n",
        "    rowsum = np.array(features.sum(1))\n",
        "    r_inv = np.power(rowsum, -1).flatten()\n",
        "    r_inv[np.isinf(r_inv)] = 0.\n",
        "    r_mat_inv = sp.diags(r_inv)\n",
        "    features = r_mat_inv.dot(features)\n",
        "    return sparse_to_tuple(features)\n",
        "\n",
        "\n",
        "def normalize_adj(adj):\n",
        "    \"\"\"Symmetrically normalize adjacency matrix.\"\"\"\n",
        "    adj = sp.coo_matrix(adj)\n",
        "    rowsum = np.array(adj.sum(1))\n",
        "    d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
        "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
        "    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
        "    return adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt).tocoo()\n",
        "\n",
        "\n",
        "def preprocess_adj(adj):\n",
        "    \"\"\"Preprocessing of adjacency matrix for simple GCN model and conversion to tuple representation.\"\"\"\n",
        "    adj_normalized = normalize_adj(adj + sp.eye(adj.shape[0]))\n",
        "    return sparse_to_tuple(adj_normalized)\n",
        "\n",
        "\n",
        "def construct_feed_dict(features, support, labels, labels_mask, placeholders):\n",
        "    \"\"\"Construct feed dictionary.\"\"\"\n",
        "    feed_dict = dict()\n",
        "    feed_dict.update({placeholders['labels']: labels})\n",
        "    feed_dict.update({placeholders['labels_mask']: labels_mask})\n",
        "    feed_dict.update({placeholders['features']: features})\n",
        "    feed_dict.update({placeholders['support'][i]: support[i]\n",
        "                      for i in range(len(support))})\n",
        "    feed_dict.update({placeholders['num_features_nonzero']: features[1].shape})\n",
        "    return feed_dict\n",
        "\n",
        "def clean_str(string):\n",
        "    \"\"\"\n",
        "    Tokenization/string cleaning for all datasets except for SST.\n",
        "    Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
        "    \"\"\"\n",
        "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
        "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
        "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
        "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
        "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
        "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
        "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
        "    string = re.sub(r\",\", \" , \", string)\n",
        "    string = re.sub(r\"!\", \" ! \", string)\n",
        "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
        "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
        "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
        "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
        "    return string.strip().lower()\n",
        "\n",
        "def clean_data(test_data, train_data):\n",
        "  p = open('{}/vocab.txt'.format(alldatapath), 'rb')\n",
        "  vocab = pkl.load(p)\n",
        "  p.close\n",
        "\n",
        "  doc_content_list = []\n",
        "  f = open('{}/{}.txt'.format(testdatapath, test_data), 'rb')\n",
        "  for line in f.readlines():\n",
        "      doc_content_list.append(line.strip().decode('latin1'))\n",
        "  f.close()\n",
        "\n",
        "  clean_docs = []\n",
        "  for doc_content in doc_content_list:\n",
        "      temp = clean_str(doc_content)\n",
        "      words = temp.split()\n",
        "      doc_words = []\n",
        "      for word in words:\n",
        "          if word in vocab:\n",
        "              doc_words.append(word)\n",
        "\n",
        "      doc_str = ' '.join(doc_words).strip()\n",
        "\n",
        "      clean_docs.append(doc_str)\n",
        "\n",
        "  clean_corpus_str = '\\n'.join(clean_docs)\n",
        "\n",
        "  f = open('{}/{}.clean.txt'.format(testdatapath, test_data), 'w')\n",
        "  f.write(clean_corpus_str)\n",
        "  f.close()\n",
        "\n",
        "  print('{} cleaned!'.format(test_data))\n",
        "\n",
        "def transform_test_data(test_data):\n",
        "  if(test_data == 'bio' or test_data =='scrub' or test_data =='swap'):\n",
        "    len_train = round(0.7 * len(base_set)) # length of training set\n",
        "    len_test = len(base_set)-len_train # length of test set\n",
        "  elif(test_data == 'bio_1000' or test_data =='scrub_1000' or test_data =='swap_1000'):\n",
        "    len_train = round(0.7 * len(base_set_1000)) # length of training set\n",
        "    len_test = len(base_set_1000)-len_train # length of test set\n",
        "  else: print('wrong test data')\n",
        "\n",
        "  word_embeddings_dim = 300\n",
        "  word_vector_map = {}\n",
        "  label_list = list(map(str,occupation_dict[:,0]))\n",
        "\n",
        "  doc_test_list = []\n",
        "  f = open('{}/{}_label.txt'.format(testdatapath, test_data), 'r')\n",
        "  lines = f.readlines()\n",
        "  for line in lines:\n",
        "      doc_test_list.append(line.strip())\n",
        "  f.close()\n",
        "\n",
        "  test_ids = range(len_train,len_train + len_test)\n",
        "  test_ids_str = '\\n'.join(str(index) for index in test_ids)\n",
        "  f = open('{}/{}.test.index'.format(testdatapath,test_data),'w')  \n",
        "  f.write(test_ids_str)\n",
        "  f.close()\n",
        "\n",
        "  doc_content_list = []\n",
        "  f = open('{}/{}.clean.txt'.format(testdatapath, test_data), 'r')\n",
        "  lines = f.readlines()\n",
        "  for line in lines:\n",
        "    doc_content_list.append(line.strip())\n",
        "  f.close()\n",
        "\n",
        "  # tx: feature vectors of test docs, no initial features\n",
        "  test_size = len(test_ids)\n",
        "  print(test_size)\n",
        "\n",
        "  row_tx = []\n",
        "  col_tx = []\n",
        "  data_tx = []\n",
        "  for i in range(test_size):\n",
        "      doc_vec = np.array([0.0 for k in range(word_embeddings_dim)])\n",
        "      doc_words = doc_content_list[i]\n",
        "      words = doc_words.split()\n",
        "      doc_len = len(words)\n",
        "      for word in words:\n",
        "          if word in word_vector_map:\n",
        "              word_vector = word_vector_map[word]\n",
        "              doc_vec = doc_vec + np.array(word_vector)\n",
        "\n",
        "      for j in range(word_embeddings_dim):\n",
        "          row_tx.append(i)\n",
        "          col_tx.append(j)\n",
        "          # np.random.uniform(-0.25, 0.25)\n",
        "          data_tx.append(doc_vec[j] / doc_len)  # doc_vec[j] / doc_len\n",
        "\n",
        "  # tx = sp.csr_matrix((test_size, word_embeddings_dim), dtype=np.float32)\n",
        "  tx = sp.csr_matrix((data_tx, (row_tx, col_tx)),\n",
        "                    shape=(test_size, word_embeddings_dim))\n",
        "  print(tx.shape)\n",
        "  ty = []\n",
        "  for i in range(test_size):\n",
        "      doc_meta = doc_test_list[i]\n",
        "      temp = doc_meta.split('\\t') #\n",
        "      label = temp[2]\n",
        "      one_hot = [0 for l in range(len(label_list))]\n",
        "      label_index = label_list.index(label)\n",
        "      one_hot[label_index] = 1\n",
        "      ty.append(one_hot)\n",
        "  ty = np.array(ty)\n",
        "  print(ty.shape)\n",
        "\n",
        "  f = open(\"{}/ind.{}.ty\".format(testdatapath, test_data), 'wb')\n",
        "  pkl.dump(ty, f)\n",
        "  f.close()\n",
        "  \n",
        "  f = open(\"{}/ind.{}.tx\".format(testdatapath, test_data), 'wb')\n",
        "  pkl.dump(tx, f)\n",
        "  f.close()\n",
        "\n",
        "  print('{} test data feature vectors and one hot labels saved!'.format(test_data))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QuqLJyWTjBLm"
      },
      "source": [
        "# Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "KBZfrJW8uvzz"
      },
      "source": [
        "## Clean Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TtQE9KQixMsu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6f575075-a519-430c-85f6-a2e3ca1e723f"
      },
      "source": [
        "if(clean == True):\n",
        "\n",
        "  start = timeit.default_timer()\n",
        "\n",
        "  clean_data('bio', 'bio') # takes a 8 mins in total\n",
        "\n",
        "  stop = timeit.default_timer()\n",
        "  print('Time: ', stop - start)  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bio cleaned!\n",
            "Time:  417.7702201269999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JKv7salguyZZ"
      },
      "source": [
        "##Build Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JSxuS-sZ7BNZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "9ada36d2-7ece-4d2a-b1a1-11e2230ba8c0"
      },
      "source": [
        "transform_test_data('bio')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29339\n",
            "(29339, 300)\n",
            "(29339, 28)\n",
            "bio test data feature vectors and one hot labels saved!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eO-XwrSb5Hps"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yYwvWhg_Izbt"
      },
      "source": [
        "## Initialisations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VCKdEo6Y5Gns",
        "colab": {}
      },
      "source": [
        "def glorot(shape, name=None):\n",
        "    \"\"\"Glorot & Bengio (AISTATS 2010) init.\"\"\"\n",
        "    init_range = np.sqrt(6.0/(shape[0]+shape[1]))\n",
        "    initial = tf.random_uniform(shape, minval=-init_range, maxval=init_range, dtype=tf.float32)\n",
        "    return tf.Variable(initial, name=name)\n",
        "\n",
        "\n",
        "def zeros(shape, name=None):\n",
        "    \"\"\"All zeros.\"\"\"\n",
        "    initial = tf.zeros(shape, dtype=tf.float32)\n",
        "    return tf.Variable(initial, name=name)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eWB93fdx48QT"
      },
      "source": [
        "## Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s_rEzztv43lN",
        "colab": {}
      },
      "source": [
        "#from inits import *\n",
        "\n",
        "flags = tf.app.flags\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "# global unique layer ID dictionary for layer name assignment\n",
        "_LAYER_UIDS = {}\n",
        "\n",
        "\n",
        "def get_layer_uid(layer_name=''):\n",
        "    \"\"\"Helper function, assigns unique layer IDs.\"\"\"\n",
        "    if layer_name not in _LAYER_UIDS:\n",
        "        _LAYER_UIDS[layer_name] = 1\n",
        "        return 1\n",
        "    else:\n",
        "        _LAYER_UIDS[layer_name] += 1\n",
        "        return _LAYER_UIDS[layer_name]\n",
        "\n",
        "\n",
        "def sparse_dropout(x, keep_prob, noise_shape):\n",
        "    \"\"\"Dropout for sparse tensors.\"\"\"\n",
        "    random_tensor = keep_prob\n",
        "    random_tensor += tf.random_uniform(noise_shape)\n",
        "    dropout_mask = tf.cast(tf.floor(random_tensor), dtype=tf.bool)\n",
        "    pre_out = tf.sparse_retain(x, dropout_mask)\n",
        "    return pre_out * (1./keep_prob)\n",
        "\n",
        "\n",
        "def dot(x, y, sparse=False):\n",
        "    \"\"\"Wrapper for tf.matmul (sparse vs dense).\"\"\"\n",
        "    if sparse:\n",
        "        res = tf.sparse_tensor_dense_matmul(x, y)\n",
        "    else:\n",
        "        res = tf.matmul(x, y)\n",
        "    return res\n",
        "\n",
        "\n",
        "class Layer(object):\n",
        "    \"\"\"Base layer class. Defines basic API for all layer objects.\n",
        "    Implementation inspired by keras (http://keras.io).\n",
        "    # Properties\n",
        "        name: String, defines the variable scope of the layer.\n",
        "        logging: Boolean, switches Tensorflow histogram logging on/off\n",
        "    # Methods\n",
        "        _call(inputs): Defines computation graph of layer\n",
        "            (i.e. takes input, returns output)\n",
        "        __call__(inputs): Wrapper for _call()\n",
        "        _log_vars(): Log all variables\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        allowed_kwargs = {'name', 'logging'}\n",
        "        for kwarg in kwargs.keys():\n",
        "            assert kwarg in allowed_kwargs, 'Invalid keyword argument: ' + kwarg\n",
        "        name = kwargs.get('name')\n",
        "        if not name:\n",
        "            layer = self.__class__.__name__.lower()\n",
        "            name = layer + '_' + str(get_layer_uid(layer))\n",
        "        self.name = name\n",
        "        self.vars = {}\n",
        "        logging = kwargs.get('logging', False)\n",
        "        self.logging = logging\n",
        "        self.sparse_inputs = False\n",
        "\n",
        "    def _call(self, inputs):\n",
        "        return inputs\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        with tf.name_scope(self.name):\n",
        "            if self.logging and not self.sparse_inputs:\n",
        "                tf.summary.histogram(self.name + '/inputs', inputs)\n",
        "            outputs = self._call(inputs)\n",
        "            if self.logging:\n",
        "                tf.summary.histogram(self.name + '/outputs', outputs)\n",
        "            return outputs\n",
        "\n",
        "    def _log_vars(self):\n",
        "        for var in self.vars:\n",
        "            tf.summary.histogram(self.name + '/vars/' + var, self.vars[var])\n",
        "\n",
        "class GraphConvolution(Layer):\n",
        "    \"\"\"Graph convolution layer.\"\"\"\n",
        "    def __init__(self, input_dim, output_dim, placeholders, dropout=0.,\n",
        "                 sparse_inputs=False, act=tf.nn.relu, bias=False,\n",
        "                 featureless=False, **kwargs):\n",
        "        super(GraphConvolution, self).__init__(**kwargs)\n",
        "\n",
        "        if dropout:\n",
        "            self.dropout = placeholders['dropout']\n",
        "        else:\n",
        "            self.dropout = 0.\n",
        "\n",
        "        self.act = act\n",
        "        self.support = placeholders['support']\n",
        "        self.sparse_inputs = sparse_inputs\n",
        "        self.featureless = featureless\n",
        "        self.bias = bias\n",
        "\n",
        "        # helper variable for sparse dropout\n",
        "        self.num_features_nonzero = placeholders['num_features_nonzero']\n",
        "\n",
        "        with tf.variable_scope(self.name + '_vars'):\n",
        "            for i in range(len(self.support)):\n",
        "                self.vars['weights_' + str(i)] = glorot([input_dim, output_dim],\n",
        "                                                        name='weights_' + str(i))\n",
        "            if self.bias:\n",
        "                self.vars['bias'] = zeros([output_dim], name='bias')\n",
        "\n",
        "        if self.logging:\n",
        "            self._log_vars()\n",
        "\n",
        "    def _call(self, inputs):\n",
        "        x = inputs\n",
        "\n",
        "        # dropout\n",
        "        if self.sparse_inputs:\n",
        "            x = sparse_dropout(x, 1-self.dropout, self.num_features_nonzero)\n",
        "        else:\n",
        "            x = tf.nn.dropout(x, 1-self.dropout)\n",
        "\n",
        "        # convolve\n",
        "        supports = list()\n",
        "        for i in range(len(self.support)):\n",
        "            if not self.featureless:\n",
        "                pre_sup = dot(x, self.vars['weights_' + str(i)],\n",
        "                              sparse=self.sparse_inputs)\n",
        "            else:\n",
        "                pre_sup = self.vars['weights_' + str(i)]\n",
        "            support = dot(self.support[i], pre_sup, sparse=True)\n",
        "            supports.append(support)\n",
        "        output = tf.add_n(supports)\n",
        "\n",
        "        # bias\n",
        "        if self.bias:\n",
        "            output += self.vars['bias']\n",
        "        self.embedding = output #output\n",
        "        return self.act(output)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3rCsaBlQ5epy"
      },
      "source": [
        "## Training Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oPkWExDA5dFi",
        "colab": {}
      },
      "source": [
        "def masked_softmax_cross_entropy(preds, labels, mask):\n",
        "    \"\"\"Softmax cross-entropy loss with masking.\"\"\"\n",
        "    print(preds)\n",
        "    loss = tf.nn.softmax_cross_entropy_with_logits(logits=preds, labels=labels)\n",
        "    mask = tf.cast(mask, dtype=tf.float32)\n",
        "    mask /= tf.reduce_mean(mask)\n",
        "    loss *= mask\n",
        "    return tf.reduce_mean(loss)\n",
        "\n",
        "\n",
        "def masked_accuracy(preds, labels, mask):\n",
        "    \"\"\"Accuracy with masking.\"\"\"\n",
        "    correct_prediction = tf.equal(tf.argmax(preds, 1), tf.argmax(labels, 1))\n",
        "\n",
        "    accuracy_all = tf.cast(correct_prediction, tf.float32)\n",
        "    mask = tf.cast(mask, dtype=tf.float32)\n",
        "    mask /= tf.reduce_mean(mask)\n",
        "    accuracy_all *= mask\n",
        "    return tf.reduce_mean(accuracy_all)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OvAWyh9bluZf"
      },
      "source": [
        "## GCN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nw2Lr9fglxRN",
        "colab": {}
      },
      "source": [
        "class Model(object):\n",
        "    def __init__(self, **kwargs):\n",
        "        allowed_kwargs = {'name', 'logging'}\n",
        "        for kwarg in kwargs.keys():\n",
        "            assert kwarg in allowed_kwargs, 'Invalid keyword argument: ' + kwarg\n",
        "        name = kwargs.get('name')\n",
        "        if not name:\n",
        "            name = self.__class__.__name__.lower()\n",
        "        self.name = name\n",
        "\n",
        "        logging = kwargs.get('logging', False)\n",
        "        self.logging = logging\n",
        "\n",
        "        self.vars = {}\n",
        "        self.placeholders = {}\n",
        "\n",
        "        self.layers = []\n",
        "        self.activations = []\n",
        "\n",
        "        self.inputs = None\n",
        "        self.outputs = None\n",
        "\n",
        "        self.loss = 0\n",
        "        self.accuracy = 0\n",
        "        self.optimizer = None\n",
        "        self.opt_op = None\n",
        "\n",
        "    def _build(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def build(self):\n",
        "        \"\"\" Wrapper for _build() \"\"\"\n",
        "        with tf.variable_scope(self.name):\n",
        "            self._build()\n",
        "\n",
        "        # Build sequential layer model\n",
        "        self.activations.append(self.inputs)\n",
        "        for layer in self.layers:\n",
        "            hidden = layer(self.activations[-1])\n",
        "            self.activations.append(hidden)\n",
        "        self.outputs = self.activations[-1]\n",
        "\n",
        "        # Store model variables for easy access\n",
        "        variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=self.name)\n",
        "        self.vars = {var.name: var for var in variables}\n",
        "\n",
        "        # Build metrics\n",
        "        self._loss()\n",
        "        self._accuracy()\n",
        "\n",
        "        self.opt_op = self.optimizer.minimize(self.loss)\n",
        "\n",
        "    def predict(self):\n",
        "        pass\n",
        "\n",
        "    def _loss(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def _accuracy(self):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def load(self, sess=None):\n",
        "        if not sess:\n",
        "            raise AttributeError(\"TensorFlow session not provided.\")\n",
        "        saver = tf.train.Saver(self.vars)\n",
        "        save_path = trainedmodelpath+\"/%s.ckpt\" % self.name\n",
        "        saver.restore(sess, save_path)\n",
        "        print(\"Model restored from file: %s\" % save_path)\n",
        "\n",
        "\n",
        "class GCN(Model):\n",
        "    def __init__(self, placeholders, input_dim, **kwargs):\n",
        "        super(GCN, self).__init__(**kwargs)\n",
        "\n",
        "        self.inputs = placeholders['features']\n",
        "        self.input_dim = input_dim\n",
        "        # self.input_dim = self.inputs.get_shape().as_list()[1]  # To be supported in future Tensorflow versions\n",
        "        self.output_dim = placeholders['labels'].get_shape().as_list()[1]\n",
        "        self.placeholders = placeholders\n",
        "\n",
        "        self.optimizer = tf.train.AdamOptimizer(learning_rate=FLAGS.learning_rate)\n",
        "\n",
        "        self.build()\n",
        "\n",
        "    def _loss(self):\n",
        "        # Weight decay loss\n",
        "        for var in self.layers[0].vars.values():\n",
        "            self.loss += FLAGS.weight_decay * tf.nn.l2_loss(var)\n",
        "\n",
        "        # Cross entropy error\n",
        "        self.loss += masked_softmax_cross_entropy(self.outputs, self.placeholders['labels'],\n",
        "                                                  self.placeholders['labels_mask'])\n",
        "\n",
        "    def _accuracy(self):\n",
        "        self.accuracy = masked_accuracy(self.outputs, self.placeholders['labels'],\n",
        "                                        self.placeholders['labels_mask'])\n",
        "        self.pred = tf.argmax(self.outputs, 1)\n",
        "        self.labels = tf.argmax(self.placeholders['labels'], 1)\n",
        "\n",
        "    def _build(self):\n",
        "\n",
        "        self.layers.append(GraphConvolution(input_dim=self.input_dim,\n",
        "                                            output_dim=FLAGS.hidden1,\n",
        "                                            placeholders=self.placeholders,\n",
        "                                            act=tf.nn.relu,\n",
        "                                            dropout=True,\n",
        "                                            featureless=True,\n",
        "                                            sparse_inputs=True,\n",
        "                                            logging=self.logging))\n",
        "\n",
        "        self.layers.append(GraphConvolution(input_dim=FLAGS.hidden1,\n",
        "                                            output_dim=self.output_dim,\n",
        "                                            placeholders=self.placeholders,\n",
        "                                            act=lambda x: x, #\n",
        "                                            dropout=True,\n",
        "                                            logging=self.logging))\n",
        "\n",
        "    def predict(self):\n",
        "        return tf.nn.softmax(self.outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ulnb-CO2LKny",
        "colab": {}
      },
      "source": [
        "# Settings\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
        "# 'cora', 'citeseer', 'pubmed'\n",
        "flags.DEFINE_string('f', '', 'kernel')\n",
        "# 'gcn', 'gcn_cheby', 'dense'\n",
        "flags.DEFINE_string('model', 'gcn', 'Model string.')\n",
        "flags.DEFINE_float('learning_rate', 0.02, 'Initial learning rate.')\n",
        "flags.DEFINE_integer('epochs', 200, 'Number of epochs to train.')\n",
        "flags.DEFINE_float('dropout', 0, 'Dropout rate (1 - keep probability).') # changed from 0.5\n",
        "flags.DEFINE_integer('hidden1', 200, 'Number of units in hidden layer 1.')\n",
        "flags.DEFINE_float('weight_decay', 0, 'Weight for L2 loss on embedding matrix.')  # 5e-4\n",
        "flags.DEFINE_integer('early_stopping', 10,'Tolerance for early stopping (# of epochs).')\n",
        "flags.DEFINE_integer('max_degree', 3, 'Maximum Chebyshev polynomial degree.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3DL_KuLX_p_f",
        "colab": {}
      },
      "source": [
        "def del_all_flags(FLAGS):\n",
        "    flags_dict = FLAGS._flags()    \n",
        "    keys_list = [keys for keys in flags_dict]    \n",
        "    for keys in keys_list:\n",
        "        FLAGS.__delattr__(keys)\n",
        "\n",
        "#del_all_flags(tf.flags.FLAGS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bzI9pZ7gpsZM",
        "colab": {}
      },
      "source": [
        "# Define model evaluation function\n",
        "def evaluate(features, support, labels, mask, placeholders,model):\n",
        "    t_test = time.time()\n",
        "    feed_dict_val = construct_feed_dict(\n",
        "        features, support, labels, mask, placeholders)\n",
        "    outs_val = sess.run([model.loss, model.accuracy, model.pred, model.labels], feed_dict=feed_dict_val)\n",
        "    return outs_val[0], outs_val[1], outs_val[2], outs_val[3], (time.time() - t_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F9l0gu68Jisc"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3keDg4LvJkJw"
      },
      "source": [
        "##  Load GCN Trained on Original Dataset with Gender Indicators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TZHpftbGrH8r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a476ddac-7fd1-4b82-c1c5-572ed6ea31f7"
      },
      "source": [
        "num_supports = 1\n",
        "model_func = GCN\n",
        "session_conf = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
        "sess = tf.Session(config=session_conf)\n",
        "flags.DEFINE_string('test_data', 'bio', 'train_data string.')\n",
        "flags.DEFINE_string('train_data', 'bio', 'test_data string.')\n",
        "\n",
        "adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask, train_size, test_size = load_corpus(FLAGS.test_data, FLAGS.train_data)\n",
        "features = sp.identity(features.shape[0])  \n",
        "features = preprocess_features(features)\n",
        "support = [preprocess_adj(adj)]\n",
        "placeholders = {\n",
        "    'support': [tf.sparse_placeholder(tf.float32) for _ in range(num_supports)],\n",
        "    'features': tf.sparse_placeholder(tf.float32, shape=tf.constant(features[2], dtype=tf.int64)),\n",
        "    'labels': tf.placeholder(tf.float32, shape=(None, y_train.shape[1])),\n",
        "    'labels_mask': tf.placeholder(tf.int32),\n",
        "    'dropout': tf.placeholder_with_default(0., shape=()),\n",
        "    # helper variable for sparse dropout\n",
        "    'num_features_nonzero': tf.placeholder(tf.int32)\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(61614, 300) (61614, 28) (29339, 300) (29339, 28) (98922, 300) (98922, 28)\n",
            "128261\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "C9ehPbOOrfXA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "339b6dc8-3edd-4a12-cd15-e9b5a97e09c6"
      },
      "source": [
        "train_data = 'bio'\n",
        "model1 = model_func(placeholders, input_dim=features[2][1], logging=True)\n",
        "model1.load(sess=sess)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-12-68e38a831b43>:119: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Tensor(\"graphconvolution_2/SparseTensorDenseMatMul/SparseTensorDenseMatMul:0\", shape=(?, 28), dtype=float32)\n",
            "WARNING:tensorflow:From <ipython-input-13-25236610d06a>:4: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "INFO:tensorflow:Restoring parameters from /content/gdrive/My Drive/NLP/trained model/gcn.ckpt\n",
            "Model restored from file: /content/gdrive/My Drive/NLP/trained model/gcn.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Uez4oIz2Jug8"
      },
      "source": [
        "## Predictions for Original Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oAgyGXVXtKZl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "f4db2dda-3fb2-4340-8bd0-9e299e215ab3"
      },
      "source": [
        "test_cost, test_acc, pred, labels, test_duration = evaluate(features, support, y_test, test_mask, placeholders,model1)\n",
        "print(\"Test set results:\", \"cost=\", \"{:.5f}\".format(test_cost),\n",
        "      \"accuracy=\", \"{:.5f}\".format(test_acc), \"time=\", \"{:.5f}\".format(test_duration))\n",
        "\n",
        "bio_test_pred = []\n",
        "test_labels = []\n",
        "print(len(test_mask))\n",
        "for i in range(len(test_mask)):\n",
        "    if test_mask[i]:\n",
        "        bio_test_pred.append(pred[i])\n",
        "        test_labels.append(labels[i])\n",
        "\n",
        "print(\"Test Precision, Recall and F1-Score...\")\n",
        "print(metrics.classification_report(test_labels, bio_test_pred, digits=4))\n",
        "print(\"Macro average Test Precision, Recall and F1-Score...\")\n",
        "print(metrics.precision_recall_fscore_support(test_labels, bio_test_pred, average='macro'))\n",
        "print(\"Micro average Test Precision, Recall and F1-Score...\")\n",
        "print(metrics.precision_recall_fscore_support(test_labels, bio_test_pred, average='micro'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test set results: cost= 0.75392 accuracy= 0.77674 time= 4.10298\n",
            "128261\n",
            "Test Precision, Recall and F1-Score...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7560    0.6563    0.7026       387\n",
            "           1     0.6821    0.6470    0.6641       796\n",
            "           2     0.8481    0.8582    0.8531      2686\n",
            "           3     0.9018    0.6312    0.7426       160\n",
            "           4     0.7824    0.7602    0.7711       246\n",
            "           5     0.7996    0.7425    0.7700       532\n",
            "           6     0.9385    0.8890    0.9131       721\n",
            "           7     0.7527    0.7721    0.7623       272\n",
            "           8     0.7391    0.5368    0.6220        95\n",
            "           9     0.7312    0.7300    0.7306       574\n",
            "          10     0.8438    0.4696    0.6034       115\n",
            "          11     0.6606    0.7421    0.6990      1865\n",
            "          12     0.7435    0.7155    0.7292       478\n",
            "          13     0.7003    0.6551    0.6769       838\n",
            "          14     0.7934    0.7450    0.7684       706\n",
            "          15     0.8182    0.2835    0.4211       127\n",
            "          16     0.6591    0.5370    0.5918       216\n",
            "          17     0.6494    0.5435    0.5917        92\n",
            "          18     0.8319    0.8562    0.8439      2058\n",
            "          19     0.6214    0.5505    0.5838       990\n",
            "          20     0.7371    0.6464    0.6888       707\n",
            "          21     0.8180    0.8983    0.8563     10532\n",
            "          22     0.7253    0.5512    0.6264      1250\n",
            "          23     0.8387    0.6903    0.7573       113\n",
            "          24     0.7321    0.5803    0.6474       598\n",
            "          25     0.8255    0.7287    0.7741       870\n",
            "          26     0.5351    0.5131    0.5239      1218\n",
            "          27     0.6667    0.5773    0.6188        97\n",
            "\n",
            "    accuracy                         0.7767     29339\n",
            "   macro avg     0.7547    0.6610    0.6976     29339\n",
            "weighted avg     0.7745    0.7767    0.7726     29339\n",
            "\n",
            "Macro average Test Precision, Recall and F1-Score...\n",
            "(0.7546916544690434, 0.6609595314360824, 0.6976273687502914, None)\n",
            "Micro average Test Precision, Recall and F1-Score...\n",
            "(0.7767476737448448, 0.7767476737448448, 0.7767476737448448, None)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ziN1-BtaN1iN"
      },
      "source": [
        "# Analyses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0W2ncLIu5uhv"
      },
      "source": [
        "## TPR, TPR gender gap and $\\pi_{g,y}$ for the gender \"female\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FOn-NAGMleXn",
        "colab": {}
      },
      "source": [
        "def tpr(y_hat, y, g):\n",
        "\n",
        "  '''\n",
        "  y_hat:    list/vector of predictions\n",
        "  y:        list/vector of true labels\n",
        "  g:        list of genders ('M', 'F') corresponding to y\n",
        "\n",
        "  returns two lists of TPRs (male, female) sorted by\n",
        "  the occupation code in ascending order\n",
        "  '''\n",
        "\n",
        "  import numpy as np\n",
        "  from sklearn.metrics import confusion_matrix\n",
        "\n",
        "  # male \t\n",
        "  m = [i for i, x in enumerate(np.array(g)) if np.array(g)[i]=='M']\n",
        "  y_hat_m = np.array(y_hat)[m]\n",
        "  y_m = y[m]\n",
        "  conf_mat_m = confusion_matrix(y_m, y_hat_m)\n",
        "  tp_m = np.diag(conf_mat_m)\n",
        "  fn_m = conf_mat_m.sum(axis=1) - np.diag(conf_mat_m)\n",
        "  tpr_m = tp_m/(tp_m+fn_m)\n",
        "\n",
        "  # female\n",
        "  f= [i for i, x in enumerate(np.array(g)) if np.array(g)[i]=='F']\n",
        "  y_hat_f = np.array(y_hat)[f]\n",
        "  y_f = y[f]\n",
        "  conf_mat_f = confusion_matrix(y_f, y_hat_f)\n",
        "  tp_f = np.diag(conf_mat_f)\n",
        "  fn_f = conf_mat_f.sum(axis=1) - np.diag(conf_mat_f)\n",
        "  tpr_f = tp_f/(tp_f+fn_f)\n",
        "\n",
        "  return(tpr_m, tpr_f)\n",
        "\n",
        "def gap(tpr_m, tpr_f, gender=\"F\"):\n",
        "  \n",
        "  '''\n",
        "  tpr_m:    list of TPRs for male\n",
        "  tpr_f:    list of TPRs for female\n",
        "  gender:   string indicating whether the gap \n",
        "            should be calculated from the female\n",
        "            ('F') or male ('M') perspective with\n",
        "            default 'F'\n",
        "\n",
        "  returns a list of TPR gender gaps for the chosen\n",
        "  gender sorted by the occupation code in ascending order\n",
        "  '''\n",
        "\n",
        "  if gender==\"F\":\n",
        "    gap = tpr_f - tpr_m\n",
        "  if gender == \"M\":\n",
        "    gap = tpr_m - tpr_f\n",
        "\n",
        "  return(gap)\n",
        "\n",
        "def prob_pi(y, g, gender='F'):\n",
        "\n",
        "  '''\n",
        "  y:        list/vector of true labels\n",
        "  g:        list of genders ('M', 'F') corresponding to y\n",
        "  gender:   string indicating whether the probability \n",
        "            should be calculated from the female\n",
        "            ('F') or male ('M') perspective with\n",
        "            default 'F'\n",
        "\n",
        "  returns a list of probabilities for the chosen\n",
        "  gender given an occupation sorted by the occupation code \n",
        "  in ascending order\n",
        "  '''\n",
        "\n",
        "  from collections import Counter\n",
        "\n",
        "  # totals\n",
        "  total_g = len(g)\n",
        "  total_y = len(y)\n",
        "  arr_y = np.array(sorted(Counter(y).items()), dtype=np.dtype('int,int'))\n",
        "  arr_y.dtype.names=['codes', 'counts']\n",
        "  counts_y = arr_y['counts']\n",
        "  p_y = counts_y/total_y # P(Y=y)\n",
        "\n",
        "  # gender filter\t\n",
        "  indx = [i for i, x in enumerate(np.array(g)) if np.array(g)[i]==gender]\n",
        "  p_g = len(indx)/total_g # P(G=g)\n",
        "  y_g = np.array(y)[indx]\n",
        "  total_y_g = len(y_g)\n",
        "  arr_y_g = np.array(sorted(Counter(y_g).items()), dtype=np.dtype('int,int'))\n",
        "  arr_y_g.dtype.names=['codes', 'counts']\n",
        "  counts_y_g = arr_y_g['counts']\n",
        "  p_y_g = counts_y_g/total_y_g # P(Y=y|G=g)\n",
        "\n",
        "  # pi\n",
        "  p_g_y = (p_y_g*p_g)/p_y # P(G=g|Y=y)\n",
        "\n",
        "  return(p_g_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JPKlnhQn6QtD",
        "colab": {}
      },
      "source": [
        "tpr_m, tpr_f = tpr(np.array(bio_test_pred), np.array(test_labels), g)\n",
        "gap_f = gap(tpr_m, tpr_f, gender= 'F')\n",
        "prob_pi_f = prob_pi(np.array(test_labels), g, gender='F')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "W1ALoI1Q6U-s"
      },
      "source": [
        "## Plot $\\text{Gap}_{female,y}$ against $\\pi_{female,y}$ and compute correlation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a9uXkQoY6xIo",
        "colab": {}
      },
      "source": [
        "def plot_gender_gap(prob_pi_g, gap_g, occupation_dict, gender='F'):\n",
        "\n",
        "  '''\n",
        "  prob_pi_g:         list of probabilities for occupations for the chosen\n",
        "                     gender\n",
        "  gap_g:             list of TPR gender gaps for the chosen\n",
        "                     gender\n",
        "  occupation_dict:   zipped list of coded occuation labels and corresponding\n",
        "                     occupation labels\n",
        "  gender:            chosen gender with 'F' as default\n",
        "\n",
        "  returns a plot of the TPR gender gaps against the probability\n",
        "  of a gender given the occupation\n",
        "  '''\n",
        "\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  # scatterplot\n",
        "  plt.plot(prob_pi_g, gap_g, 'b.')\n",
        "  \n",
        "  # x and y labels\n",
        "  if gender==\"F\":\n",
        "    plt.xlabel(\"% Female\")\n",
        "  else:\n",
        "    plt.xlabel(\"% Male\")\n",
        "  plt.ylabel(\"TRP Gender Gap\")\n",
        "  \n",
        "  # add occupation labels for each point\n",
        "  _, occupation = zip(*occupation_dict)\n",
        "  coordinates = list(zip(occupation, prob_pi_g, gap_g))\n",
        "  #for x in coordinates: plt.annotate(x[0], (x[1],x[2]), textcoords=\"offset points\",xytext=(0,10),ha='left', fontsize='small')\n",
        "  plt.annotate(coordinates[0][0], (coordinates[0][1],coordinates[0][2]), textcoords=\"offset points\",xytext=(4,16),ha='left', fontsize='small')\n",
        "  plt.annotate(coordinates[1][0], (coordinates[1][1],coordinates[1][2]), textcoords=\"offset points\",xytext=(0,5),ha='left', fontsize='small')\n",
        "  plt.annotate(coordinates[2][0], (coordinates[2][1],coordinates[2][2]), textcoords=\"offset points\",xytext=(-11,10),ha='left', fontsize='small')\n",
        "  plt.annotate(coordinates[3][0], (coordinates[3][1],coordinates[3][2]), textcoords=\"offset points\",xytext=(-35,-10),ha='left', fontsize='small')\n",
        "  plt.annotate(coordinates[4][0], (coordinates[4][1],coordinates[4][2]), textcoords=\"offset points\",xytext=(-3,-9),ha='left', fontsize='small')\n",
        "  plt.annotate(coordinates[5][0], (coordinates[5][1],coordinates[5][2]), textcoords=\"offset points\",xytext=(-1,-10),ha='left', fontsize='small')\n",
        "  plt.annotate(coordinates[6][0], (coordinates[6][1],coordinates[6][2]), textcoords=\"offset points\",xytext=(-20,7),ha='left', fontsize='small')\n",
        "  plt.annotate(coordinates[7][0], (coordinates[7][1],coordinates[7][2]), textcoords=\"offset points\",xytext=(-25,7),ha='left', fontsize='small')\n",
        "  plt.annotate(coordinates[8][0], (coordinates[8][1],coordinates[8][2]), textcoords=\"offset points\",xytext=(-8,-9),ha='left', fontsize='small')\n",
        "  plt.annotate(coordinates[9][0], (coordinates[9][1],coordinates[9][2]), textcoords=\"offset points\",xytext=(-20,6),ha='left', fontsize='small')\n",
        "  plt.annotate(coordinates[10][0], (coordinates[10][1],coordinates[10][2]), textcoords=\"offset points\",xytext=(-30,-9),ha='left', fontsize='small')\n",
        "  plt.annotate(coordinates[11][0], (coordinates[11][1],coordinates[11][2]), textcoords=\"offset points\",xytext=(0,-10),ha='left', fontsize='small')\n",
        "  plt.annotate(coordinates[12][0], (coordinates[12][1],coordinates[12][2]), textcoords=\"offset points\",xytext=(-8,-9),ha='left', fontsize='small')\n",
        "  plt.annotate(coordinates[13][0], (coordinates[13][1],coordinates[13][2]), textcoords=\"offset points\",xytext=(-10,7),ha='left', fontsize='small')\n",
        "  plt.annotate(coordinates[14][0], (coordinates[14][1],coordinates[14][2]), textcoords=\"offset points\",xytext=(10,-10),ha='left', fontsize='small')\n",
        "  plt.annotate(coordinates[15][0], (coordinates[15][1],coordinates[15][2]), textcoords=\"offset points\",xytext=(0,-9),ha='left', fontsize='small')\n",
        "  plt.annotate(coordinates[16][0], (coordinates[16][1],coordinates[16][2]), textcoords=\"offset points\",xytext=(0,7),ha='left', fontsize='small')\n",
        "  plt.annotate(coordinates[17][0], (coordinates[17][1],coordinates[17][2]), textcoords=\"offset points\",xytext=(0,-9),ha='left', fontsize='small')\n",
        "  plt.annotate(coordinates[18][0], (coordinates[18][1],coordinates[18][2]), textcoords=\"offset points\",xytext=(-50,-12),ha='left', fontsize='small')\n",
        "  plt.annotate(coordinates[19][0], (coordinates[19][1],coordinates[19][2]), textcoords=\"offset points\",xytext=(5,-2),ha='left', fontsize='small')\n",
        "  plt.annotate(coordinates[20][0], (coordinates[20][1],coordinates[20][2]), textcoords=\"offset points\",xytext=(-11,-9),ha='left', fontsize='small')\n",
        "  plt.annotate(coordinates[21][0], (coordinates[21][1],coordinates[21][2]), textcoords=\"offset points\",xytext=(0,-2),ha='left', fontsize='small')\n",
        "  plt.annotate(coordinates[22][0], (coordinates[22][1],coordinates[22][2]), textcoords=\"offset points\",xytext=(-3,-9),ha='left', fontsize='small')\n",
        "  plt.annotate(coordinates[23][0], (coordinates[23][1],coordinates[23][2]), textcoords=\"offset points\",xytext=(-11,-9),ha='left', fontsize='small')\n",
        "  plt.annotate(coordinates[24][0], (coordinates[24][1],coordinates[24][2]), textcoords=\"offset points\",xytext=(-20,6),ha='left', fontsize='small')\n",
        "  plt.annotate(coordinates[25][0], (coordinates[25][1],coordinates[25][2]), textcoords=\"offset points\",xytext=(-10,-11),ha='left', fontsize='small')\n",
        "  plt.annotate(coordinates[26][0], (coordinates[26][1],coordinates[26][2]), textcoords=\"offset points\",xytext=(-8,5),ha='left', fontsize='small')\n",
        "  plt.annotate(coordinates[27][0], (coordinates[27][1],coordinates[27][2]), textcoords=\"offset points\",xytext=(-8,8),ha='left', fontsize='small')\n",
        "  \n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zOUIMx0d6ylf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "043ede14-c8cd-4ae1-c5aa-ac1d408e8228"
      },
      "source": [
        "plot_gender_gap(prob_pi_f, gap_f, occupation_dict, 'F')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XpDSePE_Hw35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9e504d12-0861-455b-f962-2a982b2d9c4e"
      },
      "source": [
        "corr_w = np.corrcoef(prob_pi_f, gap_f)\n",
        "print('Correlation: ', corr_w[0,1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correlation:  0.74161268363547\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FPl891PcIW3Z"
      },
      "source": [
        "## Gender imbalance and compounding factor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z-vFHX36nPWw",
        "colab": {}
      },
      "source": [
        "def g_imbalance(y, g, gender='F'):\n",
        "\n",
        "  '''\n",
        "  y:        list/vector of true labels\n",
        "  g:        list of genders ('M', 'F') corresponding to y\n",
        "  gender:   string indicating whether the imbalnce \n",
        "            should be calculated from the female\n",
        "            ('F') or male ('M') perspective with\n",
        "            default 'F'\n",
        "\n",
        "  returns a list of imbalances from the perspective of the chosen\n",
        "  gender sorted by the occupation code in ascending order\n",
        "  '''\n",
        "  \n",
        "  if gender=='F':\n",
        "    g_imbalance = prob_pi(y,g,gender='F')/prob_pi(y,g,gender='M')\n",
        "\n",
        "  if gender=='M':\n",
        "    g_imbalance = prob_pi(y,g,gender='M')/prob_pi(y,g,gender='F')\n",
        "\n",
        "  return(g_imbalance)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a4k46oo3TluO",
        "colab": {}
      },
      "source": [
        "def compounding_factor(tpr_m, tpr_f, gender='F'):\n",
        "\n",
        "  '''\n",
        "  tpr_m:    list of TPRs for male\n",
        "  tpr_f:    list of TPRs for female\n",
        "  gender:   string indicating whether the compounding  \n",
        "            factor should be calculated from the female\n",
        "            ('F') or male ('M') perspective with\n",
        "            default 'F'\n",
        "\n",
        "  returns a list of compouning factors for the chosen\n",
        "  gender sorted by the occupation code in ascending order\n",
        "  '''\n",
        "\n",
        "  if gender==\"F\":\n",
        "    comp_fac = tpr_f/tpr_m\n",
        "  if gender == \"M\":\n",
        "    comp_fac = tpr_m/tpr_f\n",
        "\n",
        "  return(comp_fac)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I7AzVKwWImZU",
        "colab": {}
      },
      "source": [
        "imbalance_f = g_imbalance(np.array(bio_test_pred), g, gender='F')\n",
        "comp_fact_f = compounding_factor(tpr_m, tpr_f, gender='F')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6DQUK-p8IqT5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 934
        },
        "outputId": "73601640-c436-4d3f-99a9-ca3215611f9e"
      },
      "source": [
        "df2 = pd.DataFrame(list(zip(imbalance_f, comp_fact_f)), columns =['Gender imbalance', 'Compounding factor'])\n",
        "print('--------------- g = female ---------------')\n",
        "display(df2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------- g = female ---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gender imbalance</th>\n",
              "      <th>Compounding factor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.639024</td>\n",
              "      <td>1.003442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.310764</td>\n",
              "      <td>0.996325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.620751</td>\n",
              "      <td>0.980255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.671642</td>\n",
              "      <td>0.919355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.219388</td>\n",
              "      <td>0.874125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.244332</td>\n",
              "      <td>0.935124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.588372</td>\n",
              "      <td>1.047826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8.964286</td>\n",
              "      <td>1.358606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.169492</td>\n",
              "      <td>0.853625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.536193</td>\n",
              "      <td>0.951726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>3.571429</td>\n",
              "      <td>1.138021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.959775</td>\n",
              "      <td>1.061670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>3.842105</td>\n",
              "      <td>2.423377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>12.066667</td>\n",
              "      <td>1.674639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.878187</td>\n",
              "      <td>0.999849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>6.333333</td>\n",
              "      <td>2.056075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.303704</td>\n",
              "      <td>0.650309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1.081081</td>\n",
              "      <td>0.947368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.590090</td>\n",
              "      <td>0.995432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.834728</td>\n",
              "      <td>1.080454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>1.006472</td>\n",
              "      <td>1.071386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.788741</td>\n",
              "      <td>0.990039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1.722063</td>\n",
              "      <td>1.166312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.134146</td>\n",
              "      <td>0.922360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.139423</td>\n",
              "      <td>0.950243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.194401</td>\n",
              "      <td>0.770715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1.774347</td>\n",
              "      <td>1.380824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2.818182</td>\n",
              "      <td>0.908642</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Gender imbalance  Compounding factor\n",
              "0           0.639024            1.003442\n",
              "1           0.310764            0.996325\n",
              "2           0.620751            0.980255\n",
              "3           0.671642            0.919355\n",
              "4           0.219388            0.874125\n",
              "5           0.244332            0.935124\n",
              "6           0.588372            1.047826\n",
              "7           8.964286            1.358606\n",
              "8           0.169492            0.853625\n",
              "9           0.536193            0.951726\n",
              "10          3.571429            1.138021\n",
              "11          0.959775            1.061670\n",
              "12          3.842105            2.423377\n",
              "13         12.066667            1.674639\n",
              "14          0.878187            0.999849\n",
              "15          6.333333            2.056075\n",
              "16          0.303704            0.650309\n",
              "17          1.081081            0.947368\n",
              "18          0.590090            0.995432\n",
              "19          0.834728            1.080454\n",
              "20          1.006472            1.071386\n",
              "21          0.788741            0.990039\n",
              "22          1.722063            1.166312\n",
              "23          0.134146            0.922360\n",
              "24          0.139423            0.950243\n",
              "25          0.194401            0.770715\n",
              "26          1.774347            1.380824\n",
              "27          2.818182            0.908642"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "O47Aepf04o9t"
      },
      "source": [
        "## Load predictions on scrubbed test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gZOaeE6y5H5F",
        "colab": {}
      },
      "source": [
        "results_scrub = pd.read_csv(alldatapath+\"/scrub.results.csv\")\n",
        "scrub_test_pred = results_scrub['predicted labels']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1g_58zPT5PdZ"
      },
      "source": [
        "## TPR, TPR gender gap and correlation between TPR gender gap and $\\pi_{female,y}$ on the scrubbed test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6dyuKRE_70sC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "15814202-68d0-4fa4-9f8d-b0a4b0a6e4c7"
      },
      "source": [
        "tpr_m_scrub, tpr_f_scrub = tpr(np.array(scrub_test_pred), np.array(test_labels), g)\n",
        "gap_f_scrub = gap(tpr_m_scrub, tpr_f_scrub, gender= 'F')\n",
        "corr_w = np.corrcoef(prob_pi_f, gap_f_scrub)\n",
        "print('Correlation: ', corr_w[0,1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correlation:  0.689206668699241\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Z9GEEnAL6_1Y"
      },
      "source": [
        "## Plot $\\text{Gap}_{female,y}$ against $\\pi_{female,y}$ for original compared to scrubbed test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fUjESrZV8ORv",
        "colab": {}
      },
      "source": [
        "def plot_gender_gap_two_sets(prob_pi_g_w, gap_g_w, prob_pi_g_wo, gap_g_wo, gender='F'):\n",
        "\n",
        "  '''\n",
        "  prob_pi_g_w:       list of probabilities for occupations for the chosen\n",
        "                     gender on the set with gender indicators\n",
        "  gap_g_w:           list of TPR gender gaps for the chosen\n",
        "                     gender on the set with gender indicators\n",
        "  prob_pi_g_wo:      list of probabilities for occupations for the chosen\n",
        "                     gender on the set without gender indicators\n",
        "  gap_g_wo:          list of TPR gender gaps for the chosen\n",
        "                     gender on the set without gender indicators\n",
        "  gender:            chosen gender with 'F' as default\n",
        "\n",
        "  returns a plot of the TPR gender gaps against the probability\n",
        "  of a gender given the occupation for both the set with and the set without\n",
        "  gender indicators including trendlines\n",
        "  '''\n",
        "\n",
        "  import matplotlib.pyplot as plt\n",
        "  from sklearn.linear_model import LinearRegression\n",
        "\n",
        "  # regressions for trendlines\n",
        "  regr_w = LinearRegression()\n",
        "  regr_w.fit(prob_pi_g_w.reshape(-1, 1), gap_g_w)\n",
        "  pred_w = regr_w.predict(prob_pi_g_w.reshape(-1, 1))\n",
        "  regr_wo = LinearRegression()\n",
        "  regr_wo.fit(prob_pi_g_wo.reshape(-1, 1), gap_g_wo)\n",
        "  pred_wo = regr_wo.predict(prob_pi_g_wo.reshape(-1, 1))\n",
        "\n",
        "  # scatterplot\n",
        "  w, = plt.plot(prob_pi_g_w, gap_g_w, 'bo', label = \"with gender indicators\")\n",
        "  plt.plot(prob_pi_g_w, pred_w, color='blue')\n",
        "  wo, = plt.plot(prob_pi_g_wo, gap_g_wo, 'c^', label = \"without gender indicators\")\n",
        "  plt.plot(prob_pi_g_wo, pred_wo, color='c')\n",
        "  \n",
        "  # x and y labels\n",
        "  if gender==\"F\":\n",
        "    plt.xlabel(\"% Female\")\n",
        "  else:\n",
        "    plt.xlabel(\"% Male\")\n",
        "  plt.ylabel(\"TRP Gender Gap\")\n",
        "\n",
        "  # add legend \n",
        "  plt.legend(loc='upper left')\n",
        "  \n",
        "  # show plot\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "COFOeQeg8mYx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "outputId": "e6ad1bcb-9442-4c48-b84a-5f972158ea29"
      },
      "source": [
        "plot_gender_gap_two_sets(prob_pi_f, gap_f, prob_pi_f, gap_f_scrub, gender='F')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kLMpSX8Y9P29"
      },
      "source": [
        "Gender imbalance and compounding factor for scrubbed test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FBNiZug89U31",
        "colab": {}
      },
      "source": [
        "imbalance_f_scrub = g_imbalance(np.array(scrub_test_pred), g, gender='F')\n",
        "comp_fact_f_scrub = compounding_factor(tpr_m_scrub, tpr_f_scrub, gender='F')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V5_R6sbn9eY_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 934
        },
        "outputId": "7ccbade5-e2bf-44d6-c174-d7a236a70777"
      },
      "source": [
        "df3 = pd.DataFrame(list(zip(imbalance_f_scrub, comp_fact_f_scrub)), columns =['Gender imbalance', 'Compounding factor'])\n",
        "print('--------------- g = female ---------------')\n",
        "display(df3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------- g = female ---------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gender imbalance</th>\n",
              "      <th>Compounding factor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.671429</td>\n",
              "      <td>1.031178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.352324</td>\n",
              "      <td>1.061956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.630146</td>\n",
              "      <td>1.006303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.707692</td>\n",
              "      <td>0.910467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.259259</td>\n",
              "      <td>0.873271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.292566</td>\n",
              "      <td>1.008417</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.589450</td>\n",
              "      <td>1.050526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10.666667</td>\n",
              "      <td>1.411858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.134328</td>\n",
              "      <td>0.698210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.597484</td>\n",
              "      <td>0.999068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>3.583333</td>\n",
              "      <td>1.102679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.942122</td>\n",
              "      <td>1.021455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>3.677419</td>\n",
              "      <td>2.361039</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>6.580952</td>\n",
              "      <td>1.353093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.901639</td>\n",
              "      <td>0.989566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>4.800000</td>\n",
              "      <td>1.532710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.275000</td>\n",
              "      <td>0.528182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1.055556</td>\n",
              "      <td>1.116541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.615705</td>\n",
              "      <td>1.008688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.848485</td>\n",
              "      <td>1.080639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.961905</td>\n",
              "      <td>1.057947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.781955</td>\n",
              "      <td>0.981997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>1.536680</td>\n",
              "      <td>1.066519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.761538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.169133</td>\n",
              "      <td>1.036006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.189831</td>\n",
              "      <td>0.777091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>1.417758</td>\n",
              "      <td>1.257223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>3.400000</td>\n",
              "      <td>0.928395</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Gender imbalance  Compounding factor\n",
              "0           0.671429            1.031178\n",
              "1           0.352324            1.061956\n",
              "2           0.630146            1.006303\n",
              "3           0.707692            0.910467\n",
              "4           0.259259            0.873271\n",
              "5           0.292566            1.008417\n",
              "6           0.589450            1.050526\n",
              "7          10.666667            1.411858\n",
              "8           0.134328            0.698210\n",
              "9           0.597484            0.999068\n",
              "10          3.583333            1.102679\n",
              "11          0.942122            1.021455\n",
              "12          3.677419            2.361039\n",
              "13          6.580952            1.353093\n",
              "14          0.901639            0.989566\n",
              "15          4.800000            1.532710\n",
              "16          0.275000            0.528182\n",
              "17          1.055556            1.116541\n",
              "18          0.615705            1.008688\n",
              "19          0.848485            1.080639\n",
              "20          0.961905            1.057947\n",
              "21          0.781955            0.981997\n",
              "22          1.536680            1.066519\n",
              "23          0.142857            0.761538\n",
              "24          0.169133            1.036006\n",
              "25          0.189831            0.777091\n",
              "26          1.417758            1.257223\n",
              "27          3.400000            0.928395"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gUjvdj9F95hF"
      },
      "source": [
        "## Proportion of compounding factors pulled towards 1 after scrubbing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rWsm1s2B94w0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5aab5b5b-219c-4b69-937e-bfd40ce90d3d"
      },
      "source": [
        "# percentage of compounding factors which are pulled towards 1\n",
        "dif = comp_fact_f_scrub-comp_fact_f\n",
        "pos=0\n",
        "neg=0\n",
        "for i in range(len(comp_fact_f)):\n",
        "  if comp_fact_f[i]>1 and dif[i]<0:\n",
        "    pos = pos+1\n",
        "  if comp_fact_f[i]<1 and dif[i]>0:\n",
        "    neg = neg+1\n",
        "print('total: ', np.round(np.sum(pos+neg)/len(comp_fact_f), decimals=3))\n",
        "print('with compounding factor > 1: ', np.round(pos/len(comp_fact_f), decimals=3))\n",
        "print('with compounding factor < 1: ', np.round(neg/len(comp_fact_f), decimals=3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total:  0.607\n",
            "with compounding factor > 1:  0.286\n",
            "with compounding factor < 1:  0.321\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
